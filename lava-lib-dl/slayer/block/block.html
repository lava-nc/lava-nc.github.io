<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Block Module &mdash; Lava  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Loss" href="../loss.html" />
    <link rel="prev" title="Blocks" href="modules.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Lava
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../lava_architecture_overview.html">Lava Architecture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#key-attributes">Key attributes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#why-do-we-need-lava">Why do we need Lava?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#lava-s-foundational-concepts">Lava’s foundational concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#processes">1. Processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#behavioral-implementations-via-processmodels">2. Behavioral implementations via ProcessModels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#composability-and-connectivity">3. Composability and connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#cross-platform-execution">4. Cross-platform execution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#lava-software-stack">Lava software stack</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started_with_lava.html">Getting Started with Lava</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html">Installing Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#1.-System-Requirements">1. System Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#2.-Getting-Started">2. Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#2.1-Cloning-Lava-and-Running-from-Source">2.1 Cloning Lava and Running from Source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#2.2-[Alternative]-Installing-Lava-from-Binaries">2.2 [Alternative] Installing Lava from Binaries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#3.-Running-Lava-on-Intel-Loihi">3. Running Lava on Intel Loihi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#4.-Lava-Developer-Guide">4. Lava Developer Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#5.-Tutorials">5. Tutorials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html">Walk through Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#1.-Usage-of-the-Process-Library">1. Usage of the Process Library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Processes">Processes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Ports-and-connections">Ports and connections</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Variables">Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Record-internal-Vars-over-time">Record internal Vars over time</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Execution">Execution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Retrieve-recorded-data">Retrieve recorded data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Learn-more-about">Learn more about</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#2.-Create-a-custom-Process">2. Create a custom Process</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Create-a-new-ProcessModel">Create a new ProcessModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Use-the-custom-SpikeGenerator">Use the custom SpikeGenerator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Execute-and-plot">Execute and plot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#id1">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#id2">Learn more about</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html">Processes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#What-is-a-Process?">What is a <em>Process</em>?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#How-to-build-a-Process?">How to build a <em>Process</em>?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Overall-architecture">Overall architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#AbstractProcess:-Defining-Vars,-Ports,-and-the-API"><em>AbstractProcess</em>: Defining <em>Vars</em>, <em>Ports</em>, and the API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#ProcessModel:-Defining-the-behavior-of-a-Process"><em>ProcessModel</em>: Defining the behavior of a <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Instantiating-the-Process">Instantiating the <em>Process</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Interacting-with-Processes">Interacting with <em>Processes</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Accessing-Vars">Accessing <em>Vars</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Using-custom-APIs">Using custom APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Executing-a-Process">Executing a <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Update-Vars">Update <em>Vars</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html"><em>ProcessModels</em></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Create-a-LIF-Process">Create a LIF <em>Process</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Create-a-Python-LeafProcessModel-that-implements-the-LIF-Process">Create a Python <em>LeafProcessModel</em> that implements the LIF <em>Process</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Setup">Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Defining-a-PyLifModel-for-LIF">Defining a <em>PyLifModel</em> for LIF</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Compile-and-run-PyLifModel">Compile and run <em>PyLifModel</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Selecting-1-ProcessModel:-More-on-LeafProcessModel-attributes-and-relations">Selecting 1 <em>ProcessModel</em>: More on <em>LeafProcessModel</em> attributes and relations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html">Execution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Configuring-and-starting-execution">Configuring and starting execution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Run-conditions">Run conditions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Run-configurations">Run configurations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Running-multiple-Processes">Running multiple <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Pausing,-resuming,-and-stopping-execution">Pausing, resuming, and stopping execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Manual-compilation-and-execution">Manual compilation and execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html">Connect processes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Building-a-network-of-Processes">Building a network of <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Create-a-connection">Create a connection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Possible-connections">Possible connections</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#There-are-some-things-to-consider-though:">There are some things to consider though:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Connect-multiple-InPorts-from-a-single-OutPort">Connect multiple <em>InPorts</em> from a single <em>OutPort</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Connecting-multiple-InPorts-to-a-single-OutPort">Connecting multiple <em>InPorts</em> to a single <em>OutPort</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html">Hierarchical <em>Processes</em> and <em>SubProcessModels</em></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-LIF-and-Dense-Processes-and-ProcessModels">Create LIF and Dense <em>Processes</em> and <em>ProcessModels</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-Dense-connection-Process">Create a Dense connection <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-Python-Dense-connection-ProcessModel-implementing-the-Loihi-Sync-Protocol-and-requiring-a-CPU-compute-resource">Create a Python Dense connection <em>ProcessModel</em> implementing the Loihi Sync Protocol and requiring a CPU compute resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-LIF-neuron-Process">Create a LIF neuron <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-Python-LIF-neuron-ProcessModel-implementing-the-Loihi-Sync-Protocol-and-requiring-a-CPU-compute-resource">Create a Python LIF neuron <em>ProcessModel</em> implementing the Loihi Sync Protocol and requiring a CPU compute resource</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-DenseLayer-Hierarchical-Process-that-encompasses-Dense-and-LIF-Process-behavior">Create a DenseLayer Hierarchical <em>Process</em> that encompasses Dense and LIF <em>Process</em> behavior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-SubProcessModel-that-implements-the-DenseLayer-Process-using-Dense-and-LIF-child-Processes">Create a <em>SubProcessModel</em> that implements the DenseLayer <em>Process</em> using Dense and LIF child <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Run-the-DenseLayer-Process">Run the DenseLayer <em>Process</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Run-Connected-DenseLayer-Processes">Run Connected DenseLayer <em>Processes</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html">Remote Memory Access</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Create-a-minimal-Process-and-ProcessModel-with-a-RefPort">Create a minimal <em>Process</em> and <em>ProcessModel</em> with a <em>RefPort</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Create-a-Python-Process-Model-implementing-the-Loihi-Sync-Protocol-and-requiring-a-CPU-compute-resource">Create a Python Process Model implementing the Loihi Sync Protocol and requiring a CPU compute resource</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Run-the-Processes">Run the <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Implicit-and-explicit-VarPorts">Implicit and explicit VarPorts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Options-to-connect-RefPorts-and-VarPorts">Options to connect RefPorts and VarPorts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html">MNIST Digit Classification with Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#This-tutorial-gives-a-bird’s-eye-view-of">This tutorial gives a bird’s-eye view of</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Our-MNIST-Classifier">Our MNIST Classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#General-Imports">General Imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Lava-Processes">Lava Processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#ProcessModels-for-Python-execution">ProcessModels for Python execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Connecting-Processes">Connecting Processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Execution-and-results">Execution and results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html">Excitatory-Inhibitory Neural Network with Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#This-tutorial-gives-a-high-level-view-of">This tutorial gives a high level view of</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#E/I-Network">E/I Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#General-imports">General imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#E/I-Network-Lava-Process">E/I Network Lava Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#ProcessModels-for-Python-execution">ProcessModels for Python execution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Rate-neurons">Rate neurons</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Defining-the-parameters-for-the-network">Defining the parameters for the network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Execution-and-Results">Execution and Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Visualizing-the-activity">Visualizing the activity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Further-analysis">Further analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Controlling-the-network">Controlling the network</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#LIF-Neurons">LIF Neurons</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#id7">Execution and Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#id8">Visualizing the activity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#id9">Controlling the network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#DIfferent-recurrent-activation-regimes">DIfferent recurrent activation regimes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Running-a-ProcessModel-bit-accurate-with-Loihi">Running a ProcessModel bit-accurate with Loihi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Execution-of-bit-accurate-model">Execution of bit accurate model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html">Spike-timing Dependent Plasticity (STDP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#STDP-from-Lavas-Process-Library">STDP from Lavas Process Library</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#The-plastic-connection-Process">The plastic connection Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#Plot-spike-trains">Plot spike trains</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#Plot-traces">Plot traces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#Plot-STDP-learning-window-and-weight-changes">Plot STDP learning window and weight changes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html">Custom Learning Rules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#2.-Loihi’s-learning-engine">2. Loihi’s learning engine</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Epoch-based-updates">Epoch-based updates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Synaptic-variables">Synaptic variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Learning-rules">Learning rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Dependencies">Dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Scaling-factors">Scaling factors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Factors">Factors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Traces">Traces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Example:-Basic-pair-based-STDP">Example: Basic pair-based STDP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Instantiating-LearningRule">Instantiating LearningRule</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#The-plastic-connection-Process">The plastic connection Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Plot-spike-trains">Plot spike trains</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Plot-traces">Plot traces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Plot-STDP-learning-window-and-weight-changes">Plot STDP learning window and weight changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html">Three Factor Learning with Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Defining-three-factor-learning-rule-interfaces-in-Lava">Defining three-factor learning rule interfaces in Lava</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Reward-modulated-Spike-Timing-Dependent-Plasticity-(R-STDP)-learning-rule">Reward-modulated Spike-Timing Dependent Plasticity (R-STDP) learning rule</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Defining-a-simple-learning-network-with-localized-reward-signals">Defining a simple learning network with localized reward signals</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Initialize-network-parameters-and-weights">Initialize network parameters and weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Generate-binary-input-and-graded-reward-spikes">Generate binary input and graded reward spikes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Initialize-Network-Processes">Initialize Network Processes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Connect-Network-Processes">Connect Network Processes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Create-monitors-to-observe-the-weight-and-trace-dynamics-during-learning">Create monitors to observe the weight and trace dynamics during learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Run-the-network">Run the network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Visualize-the-learning-results">Visualize the learning results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Plot-eligibility-trace-dynamics">Plot eligibility trace dynamics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Plot-reward-trace-dynamics">Plot reward trace dynamics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Advanced-Topic:-Implementing-custom-learning-rule-interfaces">Advanced Topic: Implementing custom learning rule interfaces</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../algorithms.html">Algorithms and Application Libraries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../dl.html">Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#lava-dl-workflow">Lava-DL Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#getting-started">Getting Started</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#slayer-2-0">SLAYER 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#bootstrap">Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code-1">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#network-exchange-netx-library">Network Exchange (NetX) Library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code-2">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#detailed-description">Detailed Description</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../slayer.html">Lava-DL SLAYER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/bootstrap.html">Lava-DL Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../netx/netx.html">Lava-DL NetX</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../dnf.html">Dynamic Neural Fields</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#what-is-lava-dnf">What is lava-dnf?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#key-features">Key features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../optimization.html">Neuromorphic Constrained Optimization Library</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#about-the-project">About the Project</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#taxonomy-of-optimization-problems">Taxonomy of Optimization Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#optimizationsolver-and-optimizationproblem-classes">OptimizationSolver and OptimizationProblem Classes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#tutorials">Tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#quadratic-programming">Quadratic Programming</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#quadratic-uncosntrained-binary-optimization">Quadratic Uncosntrained Binary Optimization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#examples">Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#solving-qp-problems">Solving QP problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#solving-qubo">Solving QUBO</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#getting-started">Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#requirements">Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#installation">Installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#alternative-installing-lava-via-conda">[Alternative] Installing Lava via Conda</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../developer_guide.html">Developer Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#lava-s-origins">Lava’s Origins</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#contact-information">Contact Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#development-roadmap">Development Roadmap</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#initial-release">Initial Release</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#how-to-contribute-to-lava">How to contribute to Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#open-an-issue">Open an Issue</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#pull-request-checklist">Pull Request Checklist</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#open-a-pull-request">Open a Pull Request</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#coding-conventions">Coding Conventions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#code-requirements">Code Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#guidelines">Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#docstring-format">Docstring Format</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#contributors">Contributors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#contributor">Contributor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#committer">Committer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-project-committers">List of lava-nc/lava Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-dnf-project-committers">List of lava-nc/lava-dnf Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-optimization-project-committers">List of lava-nc/lava-optimization Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-dl-project-committers">List of lava-nc/lava-dl Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#committer-promotion">Committer Promotion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#repository-structure">Repository Structure</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#id17">lava-nc/lava</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-dnf">lava-nc/lava-dnf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-dl">lava-nc/lava-dl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-optimization">lava-nc/lava-optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-docs">lava-nc/lava-docs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#code-of-conduct">Code of Conduct</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#licenses">Licenses</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../lava_api_documentation.html">Lava API Documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../lava/lava.html">Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/lava.magma.html">Magma</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.magma.compiler.html">lava.magma.compiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.magma.core.html">lava.magma.core</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.magma.runtime.html">lava.magma.runtime</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/lava.proc.html">Lava process library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.conv.html">lava.proc.conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.dense.html">lava.proc.dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.io.html">lava.proc.io</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.learning_rules.html">lava.proc.learning_rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.lif.html">lava.proc.lif</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.monitor.html">lava.proc.monitor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.receiver.html">lava.proc.receiver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.sdn.html">lava.proc.sdn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.spiker.html">lava.proc.spiker</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/lava.utils.html">Lava Utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.dataloader.html">lava.utils.dataloader</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-float2fixed">lava.utils.float2fixed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-profiler">lava.utils.profiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-system">lava.utils.system</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-validator">lava.utils.validator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-visualizer">lava.utils.visualizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-weightutils">lava.utils.weightutils</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html">Lava - Deep Learning</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">SLAYER</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../neuron/modules.html">Neuron</a></li>
<li class="toctree-l4"><a class="reference internal" href="../synapse/modules.html">Synapse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../spike/modules.html">Spike</a></li>
<li class="toctree-l4"><a class="reference internal" href="../axon/modules.html">Axon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dendrite/modules.html">Dendrite</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../loss.html">Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../classifier.html">Classifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../io.html">Input/Output</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto.html">Auto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../utils/modules.html">Utilities</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#indices-and-tables">Indices and tables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../bootstrap/index.html">Bootstrap (ANN-SNN training)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/block/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/ann_sampler.html">ANN Statistics Sampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/routine.html">Routine</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../bootstrap/index.html#indices-and-tables">Indices and tables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../netx/index.html">Lava-DL NetX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../netx/blocks/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../netx/hdf5.html">HDF5</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../netx/utils.html">Utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../netx/index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.html">Lava - Dynamic Neural Fields</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.connect.html">lava.lib.dnf.connect</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.connect.html#lava-lib-dnf-connect-connect">lava.lib.dnf.connect.connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.connect.html#lava-lib-dnf-connect-exceptions">lava.lib.dnf.connect.exceptions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.kernels.html">lava.lib.dnf.kernels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.kernels.html#lava-lib-dnf-kernels-kernels">lava.lib.dnf.kernels.kernels</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html">lava.lib.dnf.operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-enums">lava.lib.dnf.operations.enums</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-exceptions">lava.lib.dnf.operations.exceptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-operations">lava.lib.dnf.operations.operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-shape-handlers">lava.lib.dnf.operations.shape_handlers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.inputs.html">lava.lib.dnf.inputs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.inputs.gauss_pattern.html">lava.lib.dnf.inputs.gauss_pattern</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.inputs.rate_code_spike_gen.html">lava.lib.dnf.inputs.rate_code_spike_gen</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html">lava.lib.dnf.utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-convenience">lava.lib.dnf.utils.convenience</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-math">lava.lib.dnf.utils.math</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-plotting">lava.lib.dnf.utils.plotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-validation">lava.lib.dnf.utils.validation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.html">Lava - Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html">lava.lib.optimization.problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.bayesian.html">lava.lib.optimization.problems.bayesian</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-coefficients">lava.lib.optimization.problems.coefficients</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-constraints">lava.lib.optimization.problems.constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-cost">lava.lib.optimization.problems.cost</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-problems">lava.lib.optimization.problems.problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-variables">lava.lib.optimization.problems.variables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.html">lava.lib.optimization.solvers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.bayesian.html">lava.lib.optimization.solvers.bayesian</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.generic.html">lava.lib.optimization.solvers.generic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.qp.html">lava.lib.optimization.solvers.qp</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.utils.html">lava.lib.optimization.utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.utils.generators.html">lava.lib.optimization.utils.generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.utils.html#lava-lib-optimization-utils-solver-tuner">lava.lib.optimization.utils.solver_tuner</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Lava</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../lava_api_documentation.html">Lava API Documentation</a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Lava - Deep Learning</a></li>
          <li class="breadcrumb-item"><a href="../index.html">SLAYER</a></li>
          <li class="breadcrumb-item"><a href="modules.html">Blocks</a></li>
      <li class="breadcrumb-item active">Block Module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/lava-lib-dl/slayer/block/block.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="block-module">
<h1>Block Module<a class="headerlink" href="#block-module" title="Permalink to this heading"></a></h1>
<section id="module-lava.lib.dl.slayer.block.base">
<span id="abstract-block"></span><h2>Abstract Block<a class="headerlink" href="#module-lava.lib.dl.slayer.block.base" title="Permalink to this heading"></a></h2>
<p>Base block class</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractAffine">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractAffine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">neuron_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractAffine" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract affine transform class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights
before synaptic operation. None means no transformation.
Defaults to None.</p></li>
<li><p><strong>dynamics</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable neuron dynamics. If False, only the dendrite current
is returned. Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None
means no masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractAffine.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractAffine.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractAffine.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractAffine.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward computation method. The input can be either of <code class="docutils literal notranslate"><span class="pre">NCT</span></code> or
<code class="docutils literal notranslate"><span class="pre">NCHWT</span></code> format.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractAffine.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractAffine.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractAverage">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractAverage</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractAverage" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract average block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_outputs</strong> (<em>int</em>) – number of output population groups.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractAverage.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractAverage.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractAverage.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractAverage.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward computation method. The input can be either of <code class="docutils literal notranslate"><span class="pre">NCT</span></code> or
<code class="docutils literal notranslate"><span class="pre">NCHWT</span></code> format.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractAverage.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractAverage.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractConv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">neuron_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay_shift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractConv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract convolution block class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractConv.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractConv.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractConv.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward computation method. The input must be in <code class="docutils literal notranslate"><span class="pre">NCHWT</span></code> format.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractConv.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractConv.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractConvT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractConvT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">neuron_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay_shift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractConvT" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract convolution Traspose block class. This should never be
instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractConvT.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractConvT.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractConvT.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractConvT.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractConvT.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractConvT.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractDense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractDense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">neuron_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay_shift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractDense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract dense block class. This should never be instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None means no
masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractDense.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractDense.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractDense.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractDense.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward computation method. The input can be either of <code class="docutils literal notranslate"><span class="pre">NCT</span></code> or
<code class="docutils literal notranslate"><span class="pre">NCHWT</span></code> format.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractDense.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractDense.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractFlatten">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractFlatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractFlatten" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract flatten block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractFlatten.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractFlatten.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractFlatten.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractFlatten.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward computation method. The input can be either of <code class="docutils literal notranslate"><span class="pre">NCT</span></code> or
<code class="docutils literal notranslate"><span class="pre">NCHWT</span></code> format.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractInput">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractInput</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">neuron_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay_shift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractInput" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract input block class. This should never be instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of neuron parameter. Defaults to None.</p></li>
<li><p><strong>weight</strong> (<em>float</em><em>, </em><em>optional</em>) – weight for affine transform of input. None means no weight scaling.
Defaults to None.</p></li>
<li><p><strong>bias</strong> (<em>float</em><em>, </em><em>optional</em>) – bias for affine transform of input. None means no bias shift.
Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractInput.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractInput.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractInput.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractInput.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward computation method. The input can be either of <code class="docutils literal notranslate"><span class="pre">NCT</span></code> or
<code class="docutils literal notranslate"><span class="pre">NCHWT</span></code> format.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractInput.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractInput.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractKWTA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractKWTA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">neuron_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_winners</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">self_excitation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay_shift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractKWTA" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract K-Winner-Takes-All block class. This should never be
instantiated on its own. The formulation is described as below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                   + \mathbf{R}\,s_{out}[t-1]
                   + \alpha\,(N-2K)\right)\\
\mathbf{R} = \begin{bmatrix}
a &amp;-1 &amp;\cdots &amp;-1\\
-1 &amp; a &amp;\cdots &amp;-1\\
\vdots &amp;\vdots &amp;\ddots &amp;\vdots\\
-1 &amp;-1 &amp;\cdots &amp; a
\end{bmatrix},\qquad |a| &lt; 1</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>num_winners</strong> (<em>[</em><em>type</em><em>]</em>) – number of winners.</p></li>
<li><p><strong>self_excitation</strong> (<em>float</em><em>, </em><em>optional</em>) – self excitation factor. Defaults to 0.5.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractKWTA.clamp">
<span class="sig-name descname"><span class="pre">clamp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractKWTA.clamp" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractKWTA.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractKWTA.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractKWTA.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractKWTA.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward computation method. The input can be either of <code class="docutils literal notranslate"><span class="pre">NCT</span></code> or
<code class="docutils literal notranslate"><span class="pre">NCHWT</span></code> format.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractKWTA.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractKWTA.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractPool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractPool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">neuron_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay_shift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractPool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract input block class. This should never be instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of pooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of pooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of pooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of pooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractPool.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractPool.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractPool.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractPool.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward computation method. The input must be in <code class="docutils literal notranslate"><span class="pre">NCHWT</span></code> format.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractPool.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractPool.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractRecurrent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractRecurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">neuron_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay_shift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractRecurrent" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract recurrent block class. This should never be instantiated on its
own. The recurrent formulation is described below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                + \mathbf{R}\,s_{out}[t-1]\right)</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of neuron parameter.Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractRecurrent.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractRecurrent.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractRecurrent.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractRecurrent.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward computation method. The input can be either of <code class="docutils literal notranslate"><span class="pre">NCT</span></code> or
<code class="docutils literal notranslate"><span class="pre">NCHWT</span></code> format.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractRecurrent.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractRecurrent.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractResidual">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractResidual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractResidual" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractTimeDecimation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractTimeDecimation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">factor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractTimeDecimation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract time decimation block class. This should never be instantiated
on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>factor</strong> (<em>int</em><em>, </em><em>optional</em>) – number of time units to decimate in a single bin. Must be in
powers of 2.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractTimeDecimation.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractTimeDecimation.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractTimeDecimation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractTimeDecimation.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward computation method. The input can be either of <code class="docutils literal notranslate"><span class="pre">NCT</span></code> or
<code class="docutils literal notranslate"><span class="pre">NCHWT</span></code> format.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractTimeDecimation.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractTimeDecimation.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractUnpool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">AbstractUnpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">neuron_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delay_shift</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractUnpool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract Unpool block class. This should never be instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of unpooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of unpooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of unpooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of unpooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractUnpool.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractUnpool.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractUnpool.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractUnpool.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.AbstractUnpool.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.AbstractUnpool.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.base.step_delay">
<span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.base.</span></span><span class="sig-name descname"><span class="pre">step_delay</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.base.step_delay" title="Permalink to this definition"></a></dt>
<dd><p>Step delay computation. This simulates the 1 timestep delay needed
for communication between layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>module</em>) – python module instance</p></li>
<li><p><strong>x</strong> (<em>torch.tensor</em>) – Tensor data to be delayed.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.block.cuba">
<span id="current-based-leaky-integrate-and-fire-cuba-block"></span><h2>CUrrent BAsed Leaky Integrate and Fire (CUBA) Block<a class="headerlink" href="#module-lava.lib.dl.slayer.block.cuba" title="Permalink to this heading"></a></h2>
<p>CUBA-LIF layer blocks</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.AbstractCuba">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">AbstractCuba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.AbstractCuba" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract block class for Current Based Leaky Integrator neuron. This
should never be instantiated on it’s own.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.Affine">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">Affine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.Affine" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.cuba.AbstractCuba" title="lava.lib.dl.slayer.block.cuba.AbstractCuba"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractCuba</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractAffine" title="lava.lib.dl.slayer.block.base.AbstractAffine"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractAffine</span></code></a></p>
<p>CUBA LIF affine transform class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of CUBA LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights
before synaptic operation. None means no transformation.
Defaults to None.</p></li>
<li><p><strong>dynamics</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable neuron dynamics. If False, only the dendrite current
is returned. Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None
means no masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.Average">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">Average</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.Average" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractAverage" title="lava.lib.dl.slayer.block.base.AbstractAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractAverage</span></code></a></p>
<p>CUBA LIF average block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_outputs</strong> (<em>int</em>) – number of output population groups.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.Conv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.cuba.AbstractCuba" title="lava.lib.dl.slayer.block.cuba.AbstractCuba"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractCuba</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConv" title="lava.lib.dl.slayer.block.base.AbstractConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConv</span></code></a></p>
<p>CUBA LIF convolution block class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of CUBA LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.ConvT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">ConvT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.ConvT" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.cuba.AbstractCuba" title="lava.lib.dl.slayer.block.cuba.AbstractCuba"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractCuba</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConvT" title="lava.lib.dl.slayer.block.base.AbstractConvT"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConvT</span></code></a></p>
<p>CUBA LIF convolution Traspose block class. This should never be
instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of CUBA LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.Dense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">Dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.Dense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.cuba.AbstractCuba" title="lava.lib.dl.slayer.block.cuba.AbstractCuba"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractCuba</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractDense" title="lava.lib.dl.slayer.block.base.AbstractDense"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractDense</span></code></a></p>
<p>CUBA LIF dense block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of CUBA LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None means no
masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.Flatten">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">Flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.Flatten" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractFlatten" title="lava.lib.dl.slayer.block.base.AbstractFlatten"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractFlatten</span></code></a></p>
<p>CUBA LIF flatten block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.Input">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">Input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.Input" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.cuba.AbstractCuba" title="lava.lib.dl.slayer.block.cuba.AbstractCuba"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractCuba</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractInput" title="lava.lib.dl.slayer.block.base.AbstractInput"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractInput</span></code></a></p>
<p>CUBA LIF input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of CUBA LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>weight</strong> (<em>float</em><em>, </em><em>optional</em>) – weight for affine transform of input. None means no weight scaling.
Defaults to None.</p></li>
<li><p><strong>bias</strong> (<em>float</em><em>, </em><em>optional</em>) – bias for affine transform of input. None means no bias shift.
Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.KWTA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">KWTA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.KWTA" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.cuba.AbstractCuba" title="lava.lib.dl.slayer.block.cuba.AbstractCuba"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractCuba</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractKWTA" title="lava.lib.dl.slayer.block.base.AbstractKWTA"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractKWTA</span></code></a></p>
<p>CUBA LIF K-Winner-Takes-All block class. This should never be
instantiated on its own. The formulation is described as below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                   + \mathbf{R}\,s_{out}[t-1]
                   + \alpha\,(N-2K)\right)\\
\mathbf{R} = \begin{bmatrix}
a &amp;-1 &amp;\cdots &amp;-1\\
-1 &amp; a &amp;\cdots &amp;-1\\
\vdots &amp;\vdots &amp;\ddots &amp;\vdots\\
-1 &amp;-1 &amp;\cdots &amp; a
\end{bmatrix},\qquad |a| &lt; 1</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of CUBA LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>num_winners</strong> (<em>[</em><em>type</em><em>]</em>) – number of winners.</p></li>
<li><p><strong>self_excitation</strong> (<em>float</em><em>, </em><em>optional</em>) – self excitation factor. Defaults to 0.5.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.Pool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">Pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.Pool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.cuba.AbstractCuba" title="lava.lib.dl.slayer.block.cuba.AbstractCuba"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractCuba</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractPool" title="lava.lib.dl.slayer.block.base.AbstractPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractPool</span></code></a></p>
<p>CUBA LIF input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of CUBA LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of pooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of pooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of pooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of pooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.Recurrent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">Recurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.Recurrent" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.cuba.AbstractCuba" title="lava.lib.dl.slayer.block.cuba.AbstractCuba"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractCuba</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractRecurrent" title="lava.lib.dl.slayer.block.base.AbstractRecurrent"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRecurrent</span></code></a></p>
<p>CUBA LIF recurrent block class. This should never be instantiated on its
own. The recurrent formulation is described below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                + \mathbf{R}\,s_{out}[t-1]\right)</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of CUBA LIF neuron parameter.Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.TimeDecimation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">TimeDecimation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.TimeDecimation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractTimeDecimation" title="lava.lib.dl.slayer.block.base.AbstractTimeDecimation"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractTimeDecimation</span></code></a></p>
<p>CUBA LIF time decimation block class. This should never be instantiated
on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>factor</strong> (<em>int</em><em>, </em><em>optional</em>) – number of time units to decimate in a single bin. Must be in
powers of 2.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.cuba.Unpool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.cuba.</span></span><span class="sig-name descname"><span class="pre">Unpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.cuba.Unpool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.cuba.AbstractCuba" title="lava.lib.dl.slayer.block.cuba.AbstractCuba"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractCuba</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractUnpool" title="lava.lib.dl.slayer.block.base.AbstractUnpool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractUnpool</span></code></a></p>
<p>CUBA LIF Unpool block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of CUBA LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of unpooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of unpooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of unpooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of unpooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.block.rf">
<span id="resonate-and-fire-r-f-block"></span><h2>Resonate and Fire (R&amp;F) Block<a class="headerlink" href="#module-lava.lib.dl.slayer.block.rf" title="Permalink to this heading"></a></h2>
<p>Resonate and Fire layer blocks.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.AbstractRF">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">AbstractRF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.AbstractRF" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract Resonate and Fire block class. This should never be
instantiated on it’s own.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.Affine">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">Affine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.Affine" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf.AbstractRF" title="lava.lib.dl.slayer.block.rf.AbstractRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractAffine" title="lava.lib.dl.slayer.block.base.AbstractAffine"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractAffine</span></code></a></p>
<p>Resonate &amp; Fire affine transform class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights
before synaptic operation. None means no transformation.
Defaults to None.</p></li>
<li><p><strong>dynamics</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable neuron dynamics. If False, only the dendrite current
is returned. Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None
means no masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.Average">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">Average</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.Average" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractAverage" title="lava.lib.dl.slayer.block.base.AbstractAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractAverage</span></code></a></p>
<p>Resonate &amp; Fire average block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_outputs</strong> (<em>int</em>) – number of output population groups.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.Conv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf.AbstractRF" title="lava.lib.dl.slayer.block.rf.AbstractRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConv" title="lava.lib.dl.slayer.block.base.AbstractConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConv</span></code></a></p>
<p>Resonate &amp; Fire convolution block class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.ConvT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">ConvT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.ConvT" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf.AbstractRF" title="lava.lib.dl.slayer.block.rf.AbstractRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConvT" title="lava.lib.dl.slayer.block.base.AbstractConvT"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConvT</span></code></a></p>
<p>Resonate &amp; Fire convolution Traspose block class. This should never be
instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.Dense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">Dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.Dense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf.AbstractRF" title="lava.lib.dl.slayer.block.rf.AbstractRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractDense" title="lava.lib.dl.slayer.block.base.AbstractDense"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractDense</span></code></a></p>
<p>Resonate &amp; Fire dense block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None means no
masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.Flatten">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">Flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.Flatten" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractFlatten" title="lava.lib.dl.slayer.block.base.AbstractFlatten"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractFlatten</span></code></a></p>
<p>Resonate &amp; Fire flatten block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.Input">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">Input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.Input" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf.AbstractRF" title="lava.lib.dl.slayer.block.rf.AbstractRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractInput" title="lava.lib.dl.slayer.block.base.AbstractInput"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractInput</span></code></a></p>
<p>Resonate &amp; Fire input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF parameter. Defaults to None.</p></li>
<li><p><strong>weight</strong> (<em>float</em><em>, </em><em>optional</em>) – weight for affine transform of input. None means no weight scaling.
Defaults to None.</p></li>
<li><p><strong>bias</strong> (<em>float</em><em>, </em><em>optional</em>) – bias for affine transform of input. None means no bias shift.
Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.KWTA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">KWTA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.KWTA" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf.AbstractRF" title="lava.lib.dl.slayer.block.rf.AbstractRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractKWTA" title="lava.lib.dl.slayer.block.base.AbstractKWTA"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractKWTA</span></code></a></p>
<p>Resonate &amp; Fire K-Winner-Takes-All block class. This should never be
instantiated on its own. The formulation is described as below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                   + \mathbf{R}\,s_{out}[t-1]
                   + \alpha\,(N-2K)\right)\\
\mathbf{R} = \begin{bmatrix}
a &amp;-1 &amp;\cdots &amp;-1\\
-1 &amp; a &amp;\cdots &amp;-1\\
\vdots &amp;\vdots &amp;\ddots &amp;\vdots\\
-1 &amp;-1 &amp;\cdots &amp; a
\end{bmatrix},\qquad |a| &lt; 1</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>num_winners</strong> (<em>[</em><em>type</em><em>]</em>) – number of winners.</p></li>
<li><p><strong>self_excitation</strong> (<em>float</em><em>, </em><em>optional</em>) – self excitation factor. Defaults to 0.5.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.Pool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">Pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.Pool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf.AbstractRF" title="lava.lib.dl.slayer.block.rf.AbstractRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractPool" title="lava.lib.dl.slayer.block.base.AbstractPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractPool</span></code></a></p>
<p>Resonate &amp; Fire input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of pooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of pooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of pooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of pooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.Recurrent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">Recurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.Recurrent" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf.AbstractRF" title="lava.lib.dl.slayer.block.rf.AbstractRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractRecurrent" title="lava.lib.dl.slayer.block.base.AbstractRecurrent"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRecurrent</span></code></a></p>
<p>Resonate &amp; Fire recurrent block class. This should never be instantiated on its
own. The recurrent formulation is described below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                + \mathbf{R}\,s_{out}[t-1]\right)</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF parameter.Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.TimeDecimation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">TimeDecimation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.TimeDecimation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractTimeDecimation" title="lava.lib.dl.slayer.block.base.AbstractTimeDecimation"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractTimeDecimation</span></code></a></p>
<p>Resonate &amp; Fire time decimation block class. This should never be instantiated
on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>factor</strong> (<em>int</em><em>, </em><em>optional</em>) – number of time units to decimate in a single bin. Must be in
powers of 2.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf.Unpool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf.</span></span><span class="sig-name descname"><span class="pre">Unpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf.Unpool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf.AbstractRF" title="lava.lib.dl.slayer.block.rf.AbstractRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractUnpool" title="lava.lib.dl.slayer.block.base.AbstractUnpool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractUnpool</span></code></a></p>
<p>Resonate &amp; Fire Unpool block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of unpooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of unpooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of unpooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of unpooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.block.rf_iz">
<span id="resonate-and-fire-izhikevich-r-f-iz-block"></span><h2>Resonate and Fire Izhikevich (R&amp;F Iz) Block<a class="headerlink" href="#module-lava.lib.dl.slayer.block.rf_iz" title="Permalink to this heading"></a></h2>
<p>Resonate and Fire - Izhikevich layer blocks.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.AbstractRFIz">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">AbstractRFIz</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.AbstractRFIz" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract Resonate and Fire - Izhikevich block class. This should never
be instantiated on it’s own.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.Affine">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">Affine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.Affine" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf_iz.AbstractRFIz" title="lava.lib.dl.slayer.block.rf_iz.AbstractRFIz"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRFIz</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractAffine" title="lava.lib.dl.slayer.block.base.AbstractAffine"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractAffine</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich affine transform class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights
before synaptic operation. None means no transformation.
Defaults to None.</p></li>
<li><p><strong>dynamics</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable neuron dynamics. If False, only the dendrite current
is returned. Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None
means no masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.Average">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">Average</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.Average" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractAverage" title="lava.lib.dl.slayer.block.base.AbstractAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractAverage</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich average block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_outputs</strong> (<em>int</em>) – number of output population groups.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.Conv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf_iz.AbstractRFIz" title="lava.lib.dl.slayer.block.rf_iz.AbstractRFIz"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRFIz</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConv" title="lava.lib.dl.slayer.block.base.AbstractConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConv</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich convolution block class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.ConvT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">ConvT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.ConvT" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf_iz.AbstractRFIz" title="lava.lib.dl.slayer.block.rf_iz.AbstractRFIz"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRFIz</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConvT" title="lava.lib.dl.slayer.block.base.AbstractConvT"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConvT</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich convolution Traspose block class. This should never be
instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.Dense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">Dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.Dense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf_iz.AbstractRFIz" title="lava.lib.dl.slayer.block.rf_iz.AbstractRFIz"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRFIz</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractDense" title="lava.lib.dl.slayer.block.base.AbstractDense"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractDense</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich dense block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None means no
masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.Flatten">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">Flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.Flatten" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractFlatten" title="lava.lib.dl.slayer.block.base.AbstractFlatten"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractFlatten</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich flatten block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.Input">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">Input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.Input" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf_iz.AbstractRFIz" title="lava.lib.dl.slayer.block.rf_iz.AbstractRFIz"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRFIz</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractInput" title="lava.lib.dl.slayer.block.base.AbstractInput"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractInput</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>weight</strong> (<em>float</em><em>, </em><em>optional</em>) – weight for affine transform of input. None means no weight scaling.
Defaults to None.</p></li>
<li><p><strong>bias</strong> (<em>float</em><em>, </em><em>optional</em>) – bias for affine transform of input. None means no bias shift.
Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.KWTA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">KWTA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.KWTA" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf_iz.AbstractRFIz" title="lava.lib.dl.slayer.block.rf_iz.AbstractRFIz"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRFIz</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractKWTA" title="lava.lib.dl.slayer.block.base.AbstractKWTA"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractKWTA</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich K-Winner-Takes-All block class. This should never be
instantiated on its own. The formulation is described as below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                   + \mathbf{R}\,s_{out}[t-1]
                   + \alpha\,(N-2K)\right)\\
\mathbf{R} = \begin{bmatrix}
a &amp;-1 &amp;\cdots &amp;-1\\
-1 &amp; a &amp;\cdots &amp;-1\\
\vdots &amp;\vdots &amp;\ddots &amp;\vdots\\
-1 &amp;-1 &amp;\cdots &amp; a
\end{bmatrix},\qquad |a| &lt; 1</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>num_winners</strong> (<em>[</em><em>type</em><em>]</em>) – number of winners.</p></li>
<li><p><strong>self_excitation</strong> (<em>float</em><em>, </em><em>optional</em>) – self excitation factor. Defaults to 0.5.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.Pool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">Pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.Pool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf_iz.AbstractRFIz" title="lava.lib.dl.slayer.block.rf_iz.AbstractRFIz"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRFIz</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractPool" title="lava.lib.dl.slayer.block.base.AbstractPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractPool</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of pooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of pooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of pooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of pooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.Recurrent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">Recurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.Recurrent" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf_iz.AbstractRFIz" title="lava.lib.dl.slayer.block.rf_iz.AbstractRFIz"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRFIz</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractRecurrent" title="lava.lib.dl.slayer.block.base.AbstractRecurrent"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRecurrent</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich recurrent block class. This should never be instantiated on its
own. The recurrent formulation is described below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                + \mathbf{R}\,s_{out}[t-1]\right)</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF-Izhikevich neuron parameter.Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.TimeDecimation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">TimeDecimation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.TimeDecimation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractTimeDecimation" title="lava.lib.dl.slayer.block.base.AbstractTimeDecimation"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractTimeDecimation</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich time decimation block class. This should never be instantiated
on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>factor</strong> (<em>int</em><em>, </em><em>optional</em>) – number of time units to decimate in a single bin. Must be in
powers of 2.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.rf_iz.Unpool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.rf_iz.</span></span><span class="sig-name descname"><span class="pre">Unpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.rf_iz.Unpool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.rf_iz.AbstractRFIz" title="lava.lib.dl.slayer.block.rf_iz.AbstractRFIz"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRFIz</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractUnpool" title="lava.lib.dl.slayer.block.base.AbstractUnpool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractUnpool</span></code></a></p>
<p>Resonate &amp; Fire Izhikevich Unpool block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of unpooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of unpooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of unpooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of unpooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.block.alif">
<span id="adaptive-leaky-integrate-and-fire-alif-block"></span><h2>Adaptive Leaky Integrate and Fire (ALIF) Block<a class="headerlink" href="#module-lava.lib.dl.slayer.block.alif" title="Permalink to this heading"></a></h2>
<p>Adaptive Leaky Integrate and Fire block layers.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.AbstractALIF">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">AbstractALIF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.AbstractALIF" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract Leaky Integrae and Fire block. This should never be
instantiated on it’s own.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.Average">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">Average</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.Average" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractAverage" title="lava.lib.dl.slayer.block.base.AbstractAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractAverage</span></code></a></p>
<p>Adaptive LIF average block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_outputs</strong> (<em>int</em>) – number of output population groups.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.Conv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.alif.AbstractALIF" title="lava.lib.dl.slayer.block.alif.AbstractALIF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractALIF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConv" title="lava.lib.dl.slayer.block.base.AbstractConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConv</span></code></a></p>
<p>Adaptive LIF convolution block class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.ConvT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">ConvT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.ConvT" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.alif.AbstractALIF" title="lava.lib.dl.slayer.block.alif.AbstractALIF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractALIF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConvT" title="lava.lib.dl.slayer.block.base.AbstractConvT"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConvT</span></code></a></p>
<p>Adaptive LIF convolution Traspose block class. This should never be
instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.Dense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">Dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.Dense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.alif.AbstractALIF" title="lava.lib.dl.slayer.block.alif.AbstractALIF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractALIF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractDense" title="lava.lib.dl.slayer.block.base.AbstractDense"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractDense</span></code></a></p>
<p>Adaptive LIF dense block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None means no
masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.Flatten">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">Flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.Flatten" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractFlatten" title="lava.lib.dl.slayer.block.base.AbstractFlatten"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractFlatten</span></code></a></p>
<p>Adaptive LIF flatten block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.Input">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">Input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.Input" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.alif.AbstractALIF" title="lava.lib.dl.slayer.block.alif.AbstractALIF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractALIF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractInput" title="lava.lib.dl.slayer.block.base.AbstractInput"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractInput</span></code></a></p>
<p>Adaptive LIF input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>weight</strong> (<em>float</em><em>, </em><em>optional</em>) – weight for affine transform of input. None means no weight scaling.
Defaults to None.</p></li>
<li><p><strong>bias</strong> (<em>float</em><em>, </em><em>optional</em>) – bias for affine transform of input. None means no bias shift.
Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.KWTA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">KWTA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.KWTA" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.alif.AbstractALIF" title="lava.lib.dl.slayer.block.alif.AbstractALIF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractALIF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractKWTA" title="lava.lib.dl.slayer.block.base.AbstractKWTA"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractKWTA</span></code></a></p>
<p>Adaptive LIF K-Winner-Takes-All block class. This should never be
instantiated on its own. The formulation is described as below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                   + \mathbf{R}\,s_{out}[t-1]
                   + \alpha\,(N-2K)\right)\\
\mathbf{R} = \begin{bmatrix}
a &amp;-1 &amp;\cdots &amp;-1\\
-1 &amp; a &amp;\cdots &amp;-1\\
\vdots &amp;\vdots &amp;\ddots &amp;\vdots\\
-1 &amp;-1 &amp;\cdots &amp; a
\end{bmatrix},\qquad |a| &lt; 1</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>num_winners</strong> (<em>[</em><em>type</em><em>]</em>) – number of winners.</p></li>
<li><p><strong>self_excitation</strong> (<em>float</em><em>, </em><em>optional</em>) – self excitation factor. Defaults to 0.5.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.Pool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">Pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.Pool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.alif.AbstractALIF" title="lava.lib.dl.slayer.block.alif.AbstractALIF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractALIF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractPool" title="lava.lib.dl.slayer.block.base.AbstractPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractPool</span></code></a></p>
<p>Adaptive LIF input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of pooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of pooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of pooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of pooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.Recurrent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">Recurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.Recurrent" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.alif.AbstractALIF" title="lava.lib.dl.slayer.block.alif.AbstractALIF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractALIF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractRecurrent" title="lava.lib.dl.slayer.block.base.AbstractRecurrent"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRecurrent</span></code></a></p>
<p>Adaptive LIF recurrent block class. This should never be instantiated on its
own. The recurrent formulation is described below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                + \mathbf{R}\,s_{out}[t-1]\right)</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive LIF neuron parameter.Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.TimeDecimation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">TimeDecimation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.TimeDecimation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractTimeDecimation" title="lava.lib.dl.slayer.block.base.AbstractTimeDecimation"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractTimeDecimation</span></code></a></p>
<p>Adaptive LIF time decimation block class. This should never be instantiated
on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>factor</strong> (<em>int</em><em>, </em><em>optional</em>) – number of time units to decimate in a single bin. Must be in
powers of 2.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.alif.Unpool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.alif.</span></span><span class="sig-name descname"><span class="pre">Unpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.alif.Unpool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.alif.AbstractALIF" title="lava.lib.dl.slayer.block.alif.AbstractALIF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractALIF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractUnpool" title="lava.lib.dl.slayer.block.base.AbstractUnpool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractUnpool</span></code></a></p>
<p>Adaptive LIF Unpool block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive LIF neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of unpooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of unpooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of unpooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of unpooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.block.adrf">
<span id="adaptive-resonate-and-fire-ad-r-f-block"></span><h2>Adaptive Resonate and Fire (Ad R&amp;F) Block<a class="headerlink" href="#module-lava.lib.dl.slayer.block.adrf" title="Permalink to this heading"></a></h2>
<p>Adaptive Resonate and Fire - Phase Threshold layer</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.AbstractADRF">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">AbstractADRF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.AbstractADRF" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract Adaptive Resonate and Fire block. This should
never be instantiated on its own.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.Average">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">Average</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.Average" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractAverage" title="lava.lib.dl.slayer.block.base.AbstractAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractAverage</span></code></a></p>
<p>Adaptive Resonate &amp; Fire average block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_outputs</strong> (<em>int</em>) – number of output population groups.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.Conv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf.AbstractADRF" title="lava.lib.dl.slayer.block.adrf.AbstractADRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConv" title="lava.lib.dl.slayer.block.base.AbstractConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConv</span></code></a></p>
<p>Adaptive Resonate &amp; Fire convolution block class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.ConvT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">ConvT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.ConvT" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf.AbstractADRF" title="lava.lib.dl.slayer.block.adrf.AbstractADRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConvT" title="lava.lib.dl.slayer.block.base.AbstractConvT"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConvT</span></code></a></p>
<p>Adaptive Resonate &amp; Fire convolution Traspose block class. This should never be
instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.Dense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">Dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.Dense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf.AbstractADRF" title="lava.lib.dl.slayer.block.adrf.AbstractADRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractDense" title="lava.lib.dl.slayer.block.base.AbstractDense"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractDense</span></code></a></p>
<p>Adaptive Resonate &amp; Fire dense block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None means no
masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.Flatten">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">Flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.Flatten" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractFlatten" title="lava.lib.dl.slayer.block.base.AbstractFlatten"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractFlatten</span></code></a></p>
<p>Adaptive Resonate &amp; Fire flatten block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.Input">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">Input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.Input" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf.AbstractADRF" title="lava.lib.dl.slayer.block.adrf.AbstractADRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractInput" title="lava.lib.dl.slayer.block.base.AbstractInput"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractInput</span></code></a></p>
<p>Adaptive Resonate &amp; Fire input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF neuron parameter. Defaults to None.</p></li>
<li><p><strong>weight</strong> (<em>float</em><em>, </em><em>optional</em>) – weight for affine transform of input. None means no weight scaling.
Defaults to None.</p></li>
<li><p><strong>bias</strong> (<em>float</em><em>, </em><em>optional</em>) – bias for affine transform of input. None means no bias shift.
Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.KWTA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">KWTA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.KWTA" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf.AbstractADRF" title="lava.lib.dl.slayer.block.adrf.AbstractADRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractKWTA" title="lava.lib.dl.slayer.block.base.AbstractKWTA"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractKWTA</span></code></a></p>
<p>Adaptive Resonate &amp; Fire K-Winner-Takes-All block class. This should never be
instantiated on its own. The formulation is described as below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                   + \mathbf{R}\,s_{out}[t-1]
                   + \alpha\,(N-2K)\right)\\
\mathbf{R} = \begin{bmatrix}
a &amp;-1 &amp;\cdots &amp;-1\\
-1 &amp; a &amp;\cdots &amp;-1\\
\vdots &amp;\vdots &amp;\ddots &amp;\vdots\\
-1 &amp;-1 &amp;\cdots &amp; a
\end{bmatrix},\qquad |a| &lt; 1</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>num_winners</strong> (<em>[</em><em>type</em><em>]</em>) – number of winners.</p></li>
<li><p><strong>self_excitation</strong> (<em>float</em><em>, </em><em>optional</em>) – self excitation factor. Defaults to 0.5.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.Pool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">Pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.Pool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf.AbstractADRF" title="lava.lib.dl.slayer.block.adrf.AbstractADRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractPool" title="lava.lib.dl.slayer.block.base.AbstractPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractPool</span></code></a></p>
<p>Adaptive Resonate &amp; Fire input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of pooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of pooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of pooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of pooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.Recurrent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">Recurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.Recurrent" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf.AbstractADRF" title="lava.lib.dl.slayer.block.adrf.AbstractADRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractRecurrent" title="lava.lib.dl.slayer.block.base.AbstractRecurrent"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRecurrent</span></code></a></p>
<p>Adaptive Resonate &amp; Fire recurrent block class. This should never be instantiated on its
own. The recurrent formulation is described below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                + \mathbf{R}\,s_{out}[t-1]\right)</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF neuron parameter.Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.TimeDecimation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">TimeDecimation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.TimeDecimation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractTimeDecimation" title="lava.lib.dl.slayer.block.base.AbstractTimeDecimation"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractTimeDecimation</span></code></a></p>
<p>Adaptive Resonate &amp; Fire time decimation block class. This should never be instantiated
on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>factor</strong> (<em>int</em><em>, </em><em>optional</em>) – number of time units to decimate in a single bin. Must be in
powers of 2.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf.Unpool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf.</span></span><span class="sig-name descname"><span class="pre">Unpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf.Unpool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf.AbstractADRF" title="lava.lib.dl.slayer.block.adrf.AbstractADRF"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRF</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractUnpool" title="lava.lib.dl.slayer.block.base.AbstractUnpool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractUnpool</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Unpool block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of unpooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of unpooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of unpooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of unpooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.block.adrf_iz">
<span id="adaptive-resonate-and-fire-izhikevich-ad-r-f-iz-block"></span><h2>Adaptive Resonate and Fire Izhikevich (Ad R&amp;F Iz) Block<a class="headerlink" href="#module-lava.lib.dl.slayer.block.adrf_iz" title="Permalink to this heading"></a></h2>
<p>Adaptive Resonate and Fire - Izhikevich layer blocks</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">AbstractADRFIZ</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract Adaptive Resonate and Fire - Izhikevich block. This should
never be instantiated on its own.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.Average">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">Average</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.Average" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractAverage" title="lava.lib.dl.slayer.block.base.AbstractAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractAverage</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Izhikevich average block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_outputs</strong> (<em>int</em>) – number of output population groups.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.Conv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ" title="lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRFIZ</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConv" title="lava.lib.dl.slayer.block.base.AbstractConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConv</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Izhikevich convolution block class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.ConvT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">ConvT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.ConvT" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ" title="lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRFIZ</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConvT" title="lava.lib.dl.slayer.block.base.AbstractConvT"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConvT</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Izhikevich convolution Traspose block class. This should never be
instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.Dense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">Dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.Dense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ" title="lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRFIZ</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractDense" title="lava.lib.dl.slayer.block.base.AbstractDense"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractDense</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Izhikevich dense block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None means no
masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.Flatten">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">Flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.Flatten" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractFlatten" title="lava.lib.dl.slayer.block.base.AbstractFlatten"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractFlatten</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Izhikevich flatten block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.Input">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">Input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.Input" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ" title="lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRFIZ</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractInput" title="lava.lib.dl.slayer.block.base.AbstractInput"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractInput</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Izhikevich input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>weight</strong> (<em>float</em><em>, </em><em>optional</em>) – weight for affine transform of input. None means no weight scaling.
Defaults to None.</p></li>
<li><p><strong>bias</strong> (<em>float</em><em>, </em><em>optional</em>) – bias for affine transform of input. None means no bias shift.
Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.KWTA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">KWTA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.KWTA" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ" title="lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRFIZ</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractKWTA" title="lava.lib.dl.slayer.block.base.AbstractKWTA"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractKWTA</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Izhikevich K-Winner-Takes-All block class. This should never be
instantiated on its own. The formulation is described as below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                   + \mathbf{R}\,s_{out}[t-1]
                   + \alpha\,(N-2K)\right)\\
\mathbf{R} = \begin{bmatrix}
a &amp;-1 &amp;\cdots &amp;-1\\
-1 &amp; a &amp;\cdots &amp;-1\\
\vdots &amp;\vdots &amp;\ddots &amp;\vdots\\
-1 &amp;-1 &amp;\cdots &amp; a
\end{bmatrix},\qquad |a| &lt; 1</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>num_winners</strong> (<em>[</em><em>type</em><em>]</em>) – number of winners.</p></li>
<li><p><strong>self_excitation</strong> (<em>float</em><em>, </em><em>optional</em>) – self excitation factor. Defaults to 0.5.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.Pool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">Pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.Pool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ" title="lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRFIZ</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractPool" title="lava.lib.dl.slayer.block.base.AbstractPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractPool</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Izhikevich input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of pooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of pooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of pooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of pooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.Recurrent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">Recurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.Recurrent" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ" title="lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRFIZ</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractRecurrent" title="lava.lib.dl.slayer.block.base.AbstractRecurrent"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractRecurrent</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Izhikevich recurrent block class. This should never be instantiated on its
own. The recurrent formulation is described below:</p>
<div class="math">
<p><span class="math">s_\text{out}[t] = f_s\left(\mathbf{W}\,s_\text{in}[t]
                + \mathbf{R}\,s_{out}[t-1]\right)</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF-Izhikevich neuron parameter.Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag for learnable recurrent synapse. Defaults to True.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.TimeDecimation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">TimeDecimation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.TimeDecimation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractTimeDecimation" title="lava.lib.dl.slayer.block.base.AbstractTimeDecimation"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractTimeDecimation</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Izhikevich time decimation block class. This should never be instantiated
on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>factor</strong> (<em>int</em><em>, </em><em>optional</em>) – number of time units to decimate in a single bin. Must be in
powers of 2.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.adrf_iz.Unpool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">Unpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.adrf_iz.Unpool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ" title="lava.lib.dl.slayer.block.adrf_iz.AbstractADRFIZ"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractADRFIZ</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractUnpool" title="lava.lib.dl.slayer.block.base.AbstractUnpool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractUnpool</span></code></a></p>
<p>Adaptive Resonate &amp; Fire Izhikevich Unpool block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Adaptive RF-Izhikevich neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of unpooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of unpooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of unpooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of unpooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.block.sigma_delta">
<span id="sigma-delta-block-sdn"></span><h2>Sigma Delta Block (SDN)<a class="headerlink" href="#module-lava.lib.dl.slayer.block.sigma_delta" title="Permalink to this heading"></a></h2>
<p>Sigma Delta layer blocks.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">AbstractSDRelu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract Sigma Delta block class. This should never be instantiated on
it’s own.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Average">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">Average</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Average" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractAverage" title="lava.lib.dl.slayer.block.base.AbstractAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractAverage</span></code></a></p>
<p>Sigma Delta average block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_outputs</strong> (<em>int</em>) – number of output population groups.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Conv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu" title="lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractSDRelu</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConv" title="lava.lib.dl.slayer.block.base.AbstractConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConv</span></code></a></p>
<p>Sigma Delta convolution block class. This should never be instantiated on
its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Sigma Delta neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolution dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.ConvT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">ConvT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.ConvT" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu" title="lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractSDRelu</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractConvT" title="lava.lib.dl.slayer.block.base.AbstractConvT"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractConvT</span></code></a></p>
<p>Sigma Delta convolution Traspose block class. This should never be
instantiated on its own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Sigma Delta neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – kernel size.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT stride. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT padding. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – convolutionT dilation. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – number of blocked connections. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Dense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">Dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Dense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu" title="lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractSDRelu</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractDense" title="lava.lib.dl.slayer.block.base.AbstractDense"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractDense</span></code></a></p>
<p>Sigma Delta dense block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Sigma Delta neuron parameter. Defaults to None.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>mask</strong> (<em>bool array</em><em>, </em><em>optional</em>) – boolean synapse mask that only enables relevant synapses. None means no
masking is applied. Defaults to None.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Flatten">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">Flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Flatten" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractFlatten" title="lava.lib.dl.slayer.block.base.AbstractFlatten"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractFlatten</span></code></a></p>
<p>Sigma Delta flatten block class. This should never be instantiated on its
own.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Input">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">Input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Input" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu" title="lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractSDRelu</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractInput" title="lava.lib.dl.slayer.block.base.AbstractInput"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractInput</span></code></a></p>
<p>Sigma Delta input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Sigma Delta neuron parameter. Defaults to None.</p></li>
<li><p><strong>weight</strong> (<em>float</em><em>, </em><em>optional</em>) – weight for affine transform of input. None means no weight scaling.
Defaults to None.</p></li>
<li><p><strong>bias</strong> (<em>float</em><em>, </em><em>optional</em>) – bias for affine transform of input. None means no bias shift.
Defaults to None.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of
average event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Input.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Input.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Output">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">Output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">neuron_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Output" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu" title="lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractSDRelu</span></code></a></p>
<p>Sigma Delta output block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em>) – a dictionary of sigma delta neuron parameters.</p></li>
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Output.export_hdf5">
<span class="sig-name descname"><span class="pre">export_hdf5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">handle</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Output.export_hdf5" title="Permalink to this definition"></a></dt>
<dd><p>Hdf5 export method for the block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>handle</strong> (<em>file handle</em>) – hdf5 handle to export block description.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Output.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Output.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Output.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Output.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the block.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Pool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">Pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Pool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu" title="lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractSDRelu</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractPool" title="lava.lib.dl.slayer.block.base.AbstractPool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractPool</span></code></a></p>
<p>Sigma Delta input block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Sigma Delta neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of pooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of pooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of pooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of pooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.block.sigma_delta.Unpool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.block.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">Unpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.block.sigma_delta.Unpool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu" title="lava.lib.dl.slayer.block.sigma_delta.AbstractSDRelu"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractSDRelu</span></code></a>, <a class="reference internal" href="#lava.lib.dl.slayer.block.base.AbstractUnpool" title="lava.lib.dl.slayer.block.base.AbstractUnpool"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractUnpool</span></code></a></p>
<p>Sigma Delta Unpool block class. The block is 8 bit quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neuron_params</strong> (<em>dict</em><em>, </em><em>optional</em>) – a dictionary of Sigma Delta neuron parameter. Defaults to None.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of unpooling kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – stride of unpooling operation. Defaults to None.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – padding of unpooling operation. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em><em>, </em><em>optional</em>) – dilation of unpooling kernel. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – weight initialization scaling. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function pointer or lambda that is applied to synaptic weights before
synaptic operation. None means no transformation. Defaults to None.</p></li>
<li><p><strong>delay</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable axonal delay. Defaults to False.</p></li>
<li><p><strong>delay_shift</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to simulate spike propagation delay from one layer to next.
Defaults to True.</p></li>
<li><p><strong>count_log</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to return event count log. If True, an additional value of average
event rate is returned. Defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.block">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-lava.lib.dl.slayer.block" title="Permalink to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modules.html" class="btn btn-neutral float-left" title="Blocks" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../loss.html" class="btn btn-neutral float-right" title="Loss" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Intel Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script> 

</body>
</html>