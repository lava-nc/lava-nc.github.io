<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Synapse Module &mdash; Lava  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Spike" href="../spike/modules.html" />
    <link rel="prev" title="Synapse" href="modules.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Lava
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../lava_architecture_overview.html">Lava Architecture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#key-attributes">Key attributes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#why-do-we-need-lava">Why do we need Lava?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#lava-s-foundational-concepts">Lava’s foundational concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#processes">1. Processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#behavioral-implementations-via-processmodels">2. Behavioral implementations via ProcessModels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#composability-and-connectivity">3. Composability and connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#cross-platform-execution">4. Cross-platform execution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#lava-software-stack">Lava software stack</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started_with_lava.html">Getting Started with Lava</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html">Installing Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#1.-System-Requirements">1. System Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#2.-Getting-Started">2. Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#2.1-Cloning-Lava-and-Running-from-Source">2.1 Cloning Lava and Running from Source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#2.2-[Alternative]-Installing-Lava-from-Binaries">2.2 [Alternative] Installing Lava from Binaries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#3.-Running-Lava-on-Intel-Loihi">3. Running Lava on Intel Loihi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#4.-Lava-Developer-Guide">4. Lava Developer Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#5.-Tutorials">5. Tutorials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html">Walk through Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#1.-Usage-of-the-Process-Library">1. Usage of the Process Library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Processes">Processes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Ports-and-connections">Ports and connections</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Variables">Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Record-internal-Vars-over-time">Record internal Vars over time</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Execution">Execution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Retrieve-recorded-data">Retrieve recorded data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Learn-more-about">Learn more about</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#2.-Create-a-custom-Process">2. Create a custom Process</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Create-a-new-ProcessModel">Create a new ProcessModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Use-the-custom-SpikeGenerator">Use the custom SpikeGenerator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Execute-and-plot">Execute and plot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#id1">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#id2">Learn more about</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html">Processes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#What-is-a-Process?">What is a <em>Process</em>?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#How-to-build-a-Process?">How to build a <em>Process</em>?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Overall-architecture">Overall architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#AbstractProcess:-Defining-Vars,-Ports,-and-the-API"><em>AbstractProcess</em>: Defining <em>Vars</em>, <em>Ports</em>, and the API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#ProcessModel:-Defining-the-behavior-of-a-Process"><em>ProcessModel</em>: Defining the behavior of a <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Instantiating-the-Process">Instantiating the <em>Process</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Interacting-with-Processes">Interacting with <em>Processes</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Accessing-Vars">Accessing <em>Vars</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Using-custom-APIs">Using custom APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Executing-a-Process">Executing a <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Update-Vars">Update <em>Vars</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html"><em>ProcessModels</em></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Create-a-LIF-Process">Create a LIF <em>Process</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Create-a-Python-LeafProcessModel-that-implements-the-LIF-Process">Create a Python <em>LeafProcessModel</em> that implements the LIF <em>Process</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Setup">Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Defining-a-PyLifModel-for-LIF">Defining a <em>PyLifModel</em> for LIF</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Compile-and-run-PyLifModel">Compile and run <em>PyLifModel</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Selecting-1-ProcessModel:-More-on-LeafProcessModel-attributes-and-relations">Selecting 1 <em>ProcessModel</em>: More on <em>LeafProcessModel</em> attributes and relations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html">Execution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Configuring-and-starting-execution">Configuring and starting execution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Run-conditions">Run conditions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Run-configurations">Run configurations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Running-multiple-Processes">Running multiple <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Pausing,-resuming,-and-stopping-execution">Pausing, resuming, and stopping execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Manual-compilation-and-execution">Manual compilation and execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html">Connect processes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Building-a-network-of-Processes">Building a network of <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Create-a-connection">Create a connection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Possible-connections">Possible connections</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#There-are-some-things-to-consider-though:">There are some things to consider though:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Connect-multiple-InPorts-from-a-single-OutPort">Connect multiple <em>InPorts</em> from a single <em>OutPort</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Connecting-multiple-InPorts-to-a-single-OutPort">Connecting multiple <em>InPorts</em> to a single <em>OutPort</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html">Hierarchical <em>Processes</em> and <em>SubProcessModels</em></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-LIF-and-Dense-Processes-and-ProcessModels">Create LIF and Dense <em>Processes</em> and <em>ProcessModels</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-Dense-connection-Process">Create a Dense connection <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-Python-Dense-connection-ProcessModel-implementing-the-Loihi-Sync-Protocol-and-requiring-a-CPU-compute-resource">Create a Python Dense connection <em>ProcessModel</em> implementing the Loihi Sync Protocol and requiring a CPU compute resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-LIF-neuron-Process">Create a LIF neuron <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-Python-LIF-neuron-ProcessModel-implementing-the-Loihi-Sync-Protocol-and-requiring-a-CPU-compute-resource">Create a Python LIF neuron <em>ProcessModel</em> implementing the Loihi Sync Protocol and requiring a CPU compute resource</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-DenseLayer-Hierarchical-Process-that-encompasses-Dense-and-LIF-Process-behavior">Create a DenseLayer Hierarchical <em>Process</em> that encompasses Dense and LIF <em>Process</em> behavior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-SubProcessModel-that-implements-the-DenseLayer-Process-using-Dense-and-LIF-child-Processes">Create a <em>SubProcessModel</em> that implements the DenseLayer <em>Process</em> using Dense and LIF child <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Run-the-DenseLayer-Process">Run the DenseLayer <em>Process</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Run-Connected-DenseLayer-Processes">Run Connected DenseLayer <em>Processes</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html">Remote Memory Access</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Create-a-minimal-Process-and-ProcessModel-with-a-RefPort">Create a minimal <em>Process</em> and <em>ProcessModel</em> with a <em>RefPort</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Create-a-Python-Process-Model-implementing-the-Loihi-Sync-Protocol-and-requiring-a-CPU-compute-resource">Create a Python Process Model implementing the Loihi Sync Protocol and requiring a CPU compute resource</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Run-the-Processes">Run the <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Implicit-and-explicit-VarPorts">Implicit and explicit VarPorts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Options-to-connect-RefPorts-and-VarPorts">Options to connect RefPorts and VarPorts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html">MNIST Digit Classification with Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#This-tutorial-gives-a-bird’s-eye-view-of">This tutorial gives a bird’s-eye view of</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Our-MNIST-Classifier">Our MNIST Classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#General-Imports">General Imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Lava-Processes">Lava Processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#ProcessModels-for-Python-execution">ProcessModels for Python execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Connecting-Processes">Connecting Processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Execution-and-results">Execution and results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html">Excitatory-Inhibitory Neural Network with Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#This-tutorial-gives-a-high-level-view-of">This tutorial gives a high level view of</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#E/I-Network">E/I Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#General-imports">General imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#E/I-Network-Lava-Process">E/I Network Lava Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#ProcessModels-for-Python-execution">ProcessModels for Python execution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Rate-neurons">Rate neurons</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Defining-the-parameters-for-the-network">Defining the parameters for the network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Execution-and-Results">Execution and Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Visualizing-the-activity">Visualizing the activity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Further-analysis">Further analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Controlling-the-network">Controlling the network</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#LIF-Neurons">LIF Neurons</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#id7">Execution and Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#id8">Visualizing the activity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#id9">Controlling the network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#DIfferent-recurrent-activation-regimes">DIfferent recurrent activation regimes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Running-a-ProcessModel-bit-accurate-with-Loihi">Running a ProcessModel bit-accurate with Loihi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Execution-of-bit-accurate-model">Execution of bit accurate model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html">Spike-timing Dependent Plasticity (STDP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#STDP-from-Lavas-Process-Library">STDP from Lavas Process Library</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#The-plastic-connection-Process">The plastic connection Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#Plot-spike-trains">Plot spike trains</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#Plot-traces">Plot traces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#Plot-STDP-learning-window-and-weight-changes">Plot STDP learning window and weight changes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html">Custom Learning Rules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#2.-Loihi’s-learning-engine">2. Loihi’s learning engine</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Epoch-based-updates">Epoch-based updates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Synaptic-variables">Synaptic variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Learning-rules">Learning rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Dependencies">Dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Scaling-factors">Scaling factors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Factors">Factors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Traces">Traces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Example:-Basic-pair-based-STDP">Example: Basic pair-based STDP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Instantiating-LearningRule">Instantiating LearningRule</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#The-plastic-connection-Process">The plastic connection Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Plot-spike-trains">Plot spike trains</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Plot-traces">Plot traces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Plot-STDP-learning-window-and-weight-changes">Plot STDP learning window and weight changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html">Three Factor Learning with Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Defining-three-factor-learning-rule-interfaces-in-Lava">Defining three-factor learning rule interfaces in Lava</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Reward-modulated-Spike-Timing-Dependent-Plasticity-(R-STDP)-learning-rule">Reward-modulated Spike-Timing Dependent Plasticity (R-STDP) learning rule</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Defining-a-simple-learning-network-with-localized-reward-signals">Defining a simple learning network with localized reward signals</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Initialize-network-parameters-and-weights">Initialize network parameters and weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Generate-binary-input-and-graded-reward-spikes">Generate binary input and graded reward spikes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Initialize-Network-Processes">Initialize Network Processes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Connect-Network-Processes">Connect Network Processes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Create-monitors-to-observe-the-weight-and-trace-dynamics-during-learning">Create monitors to observe the weight and trace dynamics during learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Run-the-network">Run the network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Visualize-the-learning-results">Visualize the learning results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Plot-eligibility-trace-dynamics">Plot eligibility trace dynamics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Plot-reward-trace-dynamics">Plot reward trace dynamics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Advanced-Topic:-Implementing-custom-learning-rule-interfaces">Advanced Topic: Implementing custom learning rule interfaces</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../algorithms.html">Algorithms and Application Libraries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../dl.html">Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#lava-dl-workflow">Lava-DL Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#getting-started">Getting Started</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#slayer-2-0">SLAYER 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#bootstrap">Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code-1">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#network-exchange-netx-library">Network Exchange (NetX) Library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code-2">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#detailed-description">Detailed Description</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../slayer.html">Lava-DL SLAYER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/bootstrap.html">Lava-DL Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../netx/netx.html">Lava-DL NetX</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../dnf.html">Dynamic Neural Fields</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#what-is-lava-dnf">What is lava-dnf?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#key-features">Key features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../optimization.html">Neuromorphic Constrained Optimization Library</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#about-the-project">About the Project</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#taxonomy-of-optimization-problems">Taxonomy of Optimization Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#optimizationsolver-and-optimizationproblem-classes">OptimizationSolver and OptimizationProblem Classes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#tutorials">Tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#quadratic-programming">Quadratic Programming</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#quadratic-uncosntrained-binary-optimization">Quadratic Uncosntrained Binary Optimization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#examples">Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#solving-qp-problems">Solving QP problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#solving-qubo">Solving QUBO</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#getting-started">Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#requirements">Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#installation">Installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#alternative-installing-lava-via-conda">[Alternative] Installing Lava via Conda</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../developer_guide.html">Developer Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#lava-s-origins">Lava’s Origins</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#contact-information">Contact Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#development-roadmap">Development Roadmap</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#initial-release">Initial Release</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#how-to-contribute-to-lava">How to contribute to Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#open-an-issue">Open an Issue</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#pull-request-checklist">Pull Request Checklist</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#open-a-pull-request">Open a Pull Request</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#coding-conventions">Coding Conventions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#code-requirements">Code Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#guidelines">Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#docstring-format">Docstring Format</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#contributors">Contributors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#contributor">Contributor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#committer">Committer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-project-committers">List of lava-nc/lava Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-dnf-project-committers">List of lava-nc/lava-dnf Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-optimization-project-committers">List of lava-nc/lava-optimization Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-dl-project-committers">List of lava-nc/lava-dl Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#committer-promotion">Committer Promotion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#repository-structure">Repository Structure</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#id17">lava-nc/lava</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-dnf">lava-nc/lava-dnf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-dl">lava-nc/lava-dl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-optimization">lava-nc/lava-optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-docs">lava-nc/lava-docs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#code-of-conduct">Code of Conduct</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#licenses">Licenses</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../lava_api_documentation.html">Lava API Documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../lava/lava.html">Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/lava.magma.html">Magma</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.magma.compiler.html">lava.magma.compiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.magma.core.html">lava.magma.core</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.magma.runtime.html">lava.magma.runtime</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/lava.proc.html">Lava process library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.conv.html">lava.proc.conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.dense.html">lava.proc.dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.io.html">lava.proc.io</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.learning_rules.html">lava.proc.learning_rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.lif.html">lava.proc.lif</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.monitor.html">lava.proc.monitor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.receiver.html">lava.proc.receiver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.sdn.html">lava.proc.sdn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.spiker.html">lava.proc.spiker</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/lava.utils.html">Lava Utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.dataloader.html">lava.utils.dataloader</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-float2fixed">lava.utils.float2fixed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-profiler">lava.utils.profiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-system">lava.utils.system</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-validator">lava.utils.validator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-visualizer">lava.utils.visualizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-weightutils">lava.utils.weightutils</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html">Lava - Deep Learning</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">SLAYER</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../neuron/modules.html">Neuron</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="modules.html">Synapse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../spike/modules.html">Spike</a></li>
<li class="toctree-l4"><a class="reference internal" href="../axon/modules.html">Axon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dendrite/modules.html">Dendrite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../block/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../loss.html">Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../classifier.html">Classifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../io.html">Input/Output</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto.html">Auto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../utils/modules.html">Utilities</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#indices-and-tables">Indices and tables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../bootstrap/index.html">Bootstrap (ANN-SNN training)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/block/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/ann_sampler.html">ANN Statistics Sampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/routine.html">Routine</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../bootstrap/index.html#indices-and-tables">Indices and tables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../netx/index.html">Lava-DL NetX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../netx/blocks/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../netx/hdf5.html">HDF5</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../netx/utils.html">Utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../netx/index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.html">Lava - Dynamic Neural Fields</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.connect.html">lava.lib.dnf.connect</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.connect.html#lava-lib-dnf-connect-connect">lava.lib.dnf.connect.connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.connect.html#lava-lib-dnf-connect-exceptions">lava.lib.dnf.connect.exceptions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.kernels.html">lava.lib.dnf.kernels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.kernels.html#lava-lib-dnf-kernels-kernels">lava.lib.dnf.kernels.kernels</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html">lava.lib.dnf.operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-enums">lava.lib.dnf.operations.enums</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-exceptions">lava.lib.dnf.operations.exceptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-operations">lava.lib.dnf.operations.operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-shape-handlers">lava.lib.dnf.operations.shape_handlers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.inputs.html">lava.lib.dnf.inputs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.inputs.gauss_pattern.html">lava.lib.dnf.inputs.gauss_pattern</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.inputs.rate_code_spike_gen.html">lava.lib.dnf.inputs.rate_code_spike_gen</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html">lava.lib.dnf.utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-convenience">lava.lib.dnf.utils.convenience</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-math">lava.lib.dnf.utils.math</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-plotting">lava.lib.dnf.utils.plotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-validation">lava.lib.dnf.utils.validation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.html">Lava - Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html">lava.lib.optimization.problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.bayesian.html">lava.lib.optimization.problems.bayesian</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-coefficients">lava.lib.optimization.problems.coefficients</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-constraints">lava.lib.optimization.problems.constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-cost">lava.lib.optimization.problems.cost</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-problems">lava.lib.optimization.problems.problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-variables">lava.lib.optimization.problems.variables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.html">lava.lib.optimization.solvers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.bayesian.html">lava.lib.optimization.solvers.bayesian</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.generic.html">lava.lib.optimization.solvers.generic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.qp.html">lava.lib.optimization.solvers.qp</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.utils.html">lava.lib.optimization.utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.utils.generators.html">lava.lib.optimization.utils.generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.utils.html#lava-lib-optimization-utils-solver-tuner">lava.lib.optimization.utils.solver_tuner</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Lava</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../lava_api_documentation.html">Lava API Documentation</a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Lava - Deep Learning</a></li>
          <li class="breadcrumb-item"><a href="../index.html">SLAYER</a></li>
          <li class="breadcrumb-item"><a href="modules.html">Synapse</a></li>
      <li class="breadcrumb-item active">Synapse Module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/lava-lib-dl/slayer/synapse/synapse.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="synapse-module">
<h1>Synapse Module<a class="headerlink" href="#synapse-module" title="Permalink to this heading"></a></h1>
<section id="module-lava.lib.dl.slayer.synapse.layer">
<span id="real-synapse"></span><h2>Real Synapse<a class="headerlink" href="#module-lava.lib.dl.slayer.synapse.layer" title="Permalink to this heading"></a></h2>
<p>Synapse module</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.layer.</span></span><span class="sig-name descname"><span class="pre">Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Conv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Conv3d</span></code>, <a class="reference internal" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer" title="lava.lib.dl.slayer.synapse.layer.GenericLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericLayer</span></code></a></p>
<p>Convolution synapse layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of the convolution kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of the convolution. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the convolution. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the convolution. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em>) – number of blocked connections from input channel to output channel.
Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Conv.in_channels">
<span class="sig-name descname"><span class="pre">in_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Conv.in_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Conv.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Conv.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Conv.kernel">
<span class="sig-name descname"><span class="pre">kernel</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Conv.kernel" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Conv.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Conv.stride" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Conv.padding">
<span class="sig-name descname"><span class="pre">padding</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Conv.padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Conv.dilation">
<span class="sig-name descname"><span class="pre">dilation</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Conv.dilation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Conv.groups">
<span class="sig-name descname"><span class="pre">groups</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Conv.groups" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Conv.weight_norm_enabled">
<span class="sig-name descname"><span class="pre">weight_norm_enabled</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Conv.weight_norm_enabled" title="Permalink to this definition"></a></dt>
<dd><p>flag indicating weather weight norm in enabled or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Conv.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Conv.complex" title="Permalink to this definition"></a></dt>
<dd><p>False. Indicates synapse is not complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Conv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Conv.forward" title="Permalink to this definition"></a></dt>
<dd><p>Applies the synapse to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor. Typically spikes. Input is expected to be of shape
NCHWT.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dendrite accumulation / weighted spikes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.layer.</span></span><span class="sig-name descname"><span class="pre">ConvTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ConvTranspose3d</span></code>, <a class="reference internal" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer" title="lava.lib.dl.slayer.synapse.layer.GenericLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericLayer</span></code></a></p>
<p>Transposed convolution synapse layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of the transposed convolution kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of the transposed convolution. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the transposed convolution. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the transposed convolution. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em>) – number of blocked connections from input channel to output channel.
Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose.in_channels">
<span class="sig-name descname"><span class="pre">in_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose.in_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose.weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose.kernel_size">
<span class="sig-name descname"><span class="pre">kernel_size</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose.kernel_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose.stride" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose.padding">
<span class="sig-name descname"><span class="pre">padding</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose.padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose.dilation">
<span class="sig-name descname"><span class="pre">dilation</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose.dilation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose.groups">
<span class="sig-name descname"><span class="pre">groups</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose.groups" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose.weight_norm_enabled">
<span class="sig-name descname"><span class="pre">weight_norm_enabled</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose.weight_norm_enabled" title="Permalink to this definition"></a></dt>
<dd><p>flag indicating weather weight norm in enabled or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose.complex" title="Permalink to this definition"></a></dt>
<dd><p>False. Indicates synapse is not complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.ConvTranspose.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.ConvTranspose.forward" title="Permalink to this definition"></a></dt>
<dd><p>Applies the synapse to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor. Typically spikes. Input is expected to be of shape
NCHWT.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dendrite accumulation / weighted spikes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Dense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.layer.</span></span><span class="sig-name descname"><span class="pre">Dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Dense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Conv3d</span></code>, <a class="reference internal" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer" title="lava.lib.dl.slayer.synapse.layer.GenericLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericLayer</span></code></a></p>
<p>Dense synapse layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scaling factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Dense.in_channels">
<span class="sig-name descname"><span class="pre">in_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Dense.in_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Dense.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Dense.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Dense.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Dense.weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Dense.weight_norm_enabled">
<span class="sig-name descname"><span class="pre">weight_norm_enabled</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Dense.weight_norm_enabled" title="Permalink to this definition"></a></dt>
<dd><p>flag indicating weather weight norm in enabled or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Dense.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Dense.complex" title="Permalink to this definition"></a></dt>
<dd><p>False. Indicates synapse is not complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Dense.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Dense.forward" title="Permalink to this definition"></a></dt>
<dd><p>Applies the synapse to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor. Typically spikes. Input is expected to be of shape
NCT or NCHWT.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dendrite accumulation / weighted spikes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.GenericLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.layer.</span></span><span class="sig-name descname"><span class="pre">GenericLayer</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract synapse layer class.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.GenericLayer.weight_norm_enabled">
<span class="sig-name descname"><span class="pre">weight_norm_enabled</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer.weight_norm_enabled" title="Permalink to this definition"></a></dt>
<dd><p>flag indicating weather weight norm in enabled or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.GenericLayer.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer.complex" title="Permalink to this definition"></a></dt>
<dd><p>False. Indicates synapse is not complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.GenericLayer.disable_weight_norm">
<span class="sig-name descname"><span class="pre">disable_weight_norm</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer.disable_weight_norm" title="Permalink to this definition"></a></dt>
<dd><p>Disables weight normalization on synapse.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.GenericLayer.enable_weight_norm">
<span class="sig-name descname"><span class="pre">enable_weight_norm</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer.enable_weight_norm" title="Permalink to this definition"></a></dt>
<dd><p>Enables weight normalization on synapse.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.GenericLayer.grad_norm">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">grad_norm</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer.grad_norm" title="Permalink to this definition"></a></dt>
<dd><p>Norm of weight gradients. Useful for monitoring gradient flow.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.GenericLayer.pre_hook_fx">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pre_hook_fx</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer.pre_hook_fx" title="Permalink to this definition"></a></dt>
<dd><p>Returns the pre-hook function for synapse operation. Typically
intended to define the quantization method.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.GenericLayer.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the synapse</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Pool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.layer.</span></span><span class="sig-name descname"><span class="pre">Pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Pool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Conv3d</span></code>, <a class="reference internal" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer" title="lava.lib.dl.slayer.synapse.layer.GenericLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericLayer</span></code></a></p>
<p>Pooling synape layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – [description]</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of pooling. Defaults to <cite>kernel_size</cite>.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the pooling. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the pooling. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Pool.in_channels">
<span class="sig-name descname"><span class="pre">in_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Pool.in_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Pool.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Pool.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Pool.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Pool.weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Pool.kernel_size">
<span class="sig-name descname"><span class="pre">kernel_size</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Pool.kernel_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Pool.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Pool.stride" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Pool.padding">
<span class="sig-name descname"><span class="pre">padding</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Pool.padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Pool.dilation">
<span class="sig-name descname"><span class="pre">dilation</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Pool.dilation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Pool.weight_norm_enabled">
<span class="sig-name descname"><span class="pre">weight_norm_enabled</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Pool.weight_norm_enabled" title="Permalink to this definition"></a></dt>
<dd><p>flag indicating weather weight norm in enabled or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Pool.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Pool.complex" title="Permalink to this definition"></a></dt>
<dd><p>False. Indicates synapse is not complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Pool.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Pool.forward" title="Permalink to this definition"></a></dt>
<dd><p>Applies the synapse to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor. Typically spikes. Input is expected to be of shape
NCHWT.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dendrite accumulation / weighted spikes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Unpool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.layer.</span></span><span class="sig-name descname"><span class="pre">Unpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Unpool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ConvTranspose3d</span></code>, <a class="reference internal" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer" title="lava.lib.dl.slayer.synapse.layer.GenericLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericLayer</span></code></a></p>
<p>Unpooling synape layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – [description]</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of unpooling. Defaults to <cite>kernel_size</cite>.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the unpooling. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the unpooling. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Unpool.in_channels">
<span class="sig-name descname"><span class="pre">in_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Unpool.in_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Unpool.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Unpool.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Unpool.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Unpool.weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Unpool.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Unpool.stride" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Unpool.padding">
<span class="sig-name descname"><span class="pre">padding</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Unpool.padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Unpool.dilation">
<span class="sig-name descname"><span class="pre">dilation</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Unpool.dilation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Unpool.weight_norm_enabled">
<span class="sig-name descname"><span class="pre">weight_norm_enabled</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Unpool.weight_norm_enabled" title="Permalink to this definition"></a></dt>
<dd><p>flag indicating weather weight norm in enabled or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Unpool.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Unpool.complex" title="Permalink to this definition"></a></dt>
<dd><p>False. Indicates synapse is not complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.layer.Unpool.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.layer.Unpool.forward" title="Permalink to this definition"></a></dt>
<dd><p>Applies the synapse to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor. Typically spikes. Input is expected to be of shape
NCHWT.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dendrite accumulation / weighted spikes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.synapse.complex">
<span id="complex-module"></span><h2>Complex Module<a class="headerlink" href="#module-lava.lib.dl.slayer.synapse.complex" title="Permalink to this heading"></a></h2>
<p>Complex synapse</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.ComplexLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.complex.</span></span><span class="sig-name descname"><span class="pre">ComplexLayer</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract complex layer class.</p>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.ComplexLayer.disable_weight_norm">
<span class="sig-name descname"><span class="pre">disable_weight_norm</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer.disable_weight_norm" title="Permalink to this definition"></a></dt>
<dd><p>Disables weight normalization on synapse.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.ComplexLayer.enable_weight_norm">
<span class="sig-name descname"><span class="pre">enable_weight_norm</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer.enable_weight_norm" title="Permalink to this definition"></a></dt>
<dd><p>Enables weight normalization on synapse.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.ComplexLayer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forward complex synaptic operation.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.ComplexLayer.grad_norm">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">grad_norm</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer.grad_norm" title="Permalink to this definition"></a></dt>
<dd><p>Norm of weight gradients. Useful for monitoring gradient flow.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.ComplexLayer.pre_hook_fx">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pre_hook_fx</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer.pre_hook_fx" title="Permalink to this definition"></a></dt>
<dd><p>Returns the pre-hook function for synapse operation. Typically
intended to define the quantization method.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.ComplexLayer.shape">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">shape</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer.shape" title="Permalink to this definition"></a></dt>
<dd><p>Shape of the synapse</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.complex.</span></span><span class="sig-name descname"><span class="pre">Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Conv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer" title="lava.lib.dl.slayer.synapse.complex.ComplexLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComplexLayer</span></code></a></p>
<p>Convolution complex-synapse layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of the convolution kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of the convolution. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the convolution. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the convolution. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em>) – number of blocked connections from input channel to output channel.
Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Conv.real">
<span class="sig-name descname"><span class="pre">real</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Conv.real" title="Permalink to this definition"></a></dt>
<dd><p>real synapse.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#lava.lib.dl.slayer.synapse.Conv" title="lava.lib.dl.slayer.synapse.Conv">slayer.synapse.Conv</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Conv.imag">
<span class="sig-name descname"><span class="pre">imag</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Conv.imag" title="Permalink to this definition"></a></dt>
<dd><p>imaginary synapse.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#lava.lib.dl.slayer.synapse.Conv" title="lava.lib.dl.slayer.synapse.Conv">slayer.synapse.Conv</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Conv.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Conv.complex" title="Permalink to this definition"></a></dt>
<dd><p>True. Indicates synapse is complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.ConvTranspose">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.complex.</span></span><span class="sig-name descname"><span class="pre">ConvTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.ConvTranspose" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer" title="lava.lib.dl.slayer.synapse.complex.ComplexLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComplexLayer</span></code></a></p>
<p>Transposed convolution synapse layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of the transposed convolution kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of the transposed convolution. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the transposed convolution. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the transposed convolution. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em>) – number of blocked connections from input channel to output channel.
Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.ConvTranspose.real">
<span class="sig-name descname"><span class="pre">real</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.ConvTranspose.real" title="Permalink to this definition"></a></dt>
<dd><p>real synapse.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#lava.lib.dl.slayer.synapse.ConvTranspose" title="lava.lib.dl.slayer.synapse.ConvTranspose">slayer.synapse.ConvTranspose</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.ConvTranspose.imag">
<span class="sig-name descname"><span class="pre">imag</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.ConvTranspose.imag" title="Permalink to this definition"></a></dt>
<dd><p>imaginary synapse.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#lava.lib.dl.slayer.synapse.ConvTranspose" title="lava.lib.dl.slayer.synapse.ConvTranspose">slayer.synapse.ConvTranspose</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.ConvTranspose.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.ConvTranspose.complex" title="Permalink to this definition"></a></dt>
<dd><p>True. Indicates synapse is complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Dense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.complex.</span></span><span class="sig-name descname"><span class="pre">Dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Dense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer" title="lava.lib.dl.slayer.synapse.complex.ComplexLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComplexLayer</span></code></a></p>
<p>Dense compelx-synapse layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scaling factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Dense.real">
<span class="sig-name descname"><span class="pre">real</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Dense.real" title="Permalink to this definition"></a></dt>
<dd><p>real synapse.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#lava.lib.dl.slayer.synapse.Dense" title="lava.lib.dl.slayer.synapse.Dense">slayer.synapse.Dense</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Dense.imag">
<span class="sig-name descname"><span class="pre">imag</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Dense.imag" title="Permalink to this definition"></a></dt>
<dd><p>imaginary synapse.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#lava.lib.dl.slayer.synapse.Dense" title="lava.lib.dl.slayer.synapse.Dense">slayer.synapse.Dense</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Dense.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Dense.complex" title="Permalink to this definition"></a></dt>
<dd><p>True. Indicates synapse is complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Pool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.complex.</span></span><span class="sig-name descname"><span class="pre">Pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Pool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer" title="lava.lib.dl.slayer.synapse.complex.ComplexLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComplexLayer</span></code></a></p>
<p>Pooling complex-synape layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – [description]</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of pooling. Defaults to <cite>kernel_size</cite>.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the pooling. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the pooling. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Pool.real">
<span class="sig-name descname"><span class="pre">real</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Pool.real" title="Permalink to this definition"></a></dt>
<dd><p>real synapse.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#lava.lib.dl.slayer.synapse.Pool" title="lava.lib.dl.slayer.synapse.Pool">slayer.synapse.Pool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Pool.imag">
<span class="sig-name descname"><span class="pre">imag</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Pool.imag" title="Permalink to this definition"></a></dt>
<dd><p>imaginary synapse.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#lava.lib.dl.slayer.synapse.Pool" title="lava.lib.dl.slayer.synapse.Pool">slayer.synapse.Pool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Pool.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Pool.complex" title="Permalink to this definition"></a></dt>
<dd><p>True. Indicates synapse is complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Unpool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.complex.</span></span><span class="sig-name descname"><span class="pre">Unpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Unpool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.synapse.complex.ComplexLayer" title="lava.lib.dl.slayer.synapse.complex.ComplexLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">ComplexLayer</span></code></a></p>
<p>Unpooling complex-synape layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – [description]</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of unpooling. Defaults to <cite>kernel_size</cite>.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the unpooling. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the unpooling. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Unpool.real">
<span class="sig-name descname"><span class="pre">real</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Unpool.real" title="Permalink to this definition"></a></dt>
<dd><p>real synapse.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#lava.lib.dl.slayer.synapse.Unpool" title="lava.lib.dl.slayer.synapse.Unpool">slayer.synapse.Unpool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Unpool.imag">
<span class="sig-name descname"><span class="pre">imag</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Unpool.imag" title="Permalink to this definition"></a></dt>
<dd><p>imaginary synapse.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#lava.lib.dl.slayer.synapse.Unpool" title="lava.lib.dl.slayer.synapse.Unpool">slayer.synapse.Unpool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.complex.Unpool.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.complex.Unpool.complex" title="Permalink to this definition"></a></dt>
<dd><p>True. Indicates synapse is complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.synapse">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-lava.lib.dl.slayer.synapse" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Conv">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.</span></span><span class="sig-name descname"><span class="pre">Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Conv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Conv3d</span></code>, <a class="reference internal" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer" title="lava.lib.dl.slayer.synapse.layer.GenericLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericLayer</span></code></a></p>
<p>Convolution synapse layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of the convolution kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of the convolution. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the convolution. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the convolution. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em>) – number of blocked connections from input channel to output channel.
Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Conv.in_channels">
<span class="sig-name descname"><span class="pre">in_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Conv.in_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Conv.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Conv.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Conv.kernel">
<span class="sig-name descname"><span class="pre">kernel</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Conv.kernel" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Conv.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Conv.stride" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Conv.padding">
<span class="sig-name descname"><span class="pre">padding</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Conv.padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Conv.dilation">
<span class="sig-name descname"><span class="pre">dilation</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Conv.dilation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Conv.groups">
<span class="sig-name descname"><span class="pre">groups</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Conv.groups" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Conv.weight_norm_enabled">
<span class="sig-name descname"><span class="pre">weight_norm_enabled</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Conv.weight_norm_enabled" title="Permalink to this definition"></a></dt>
<dd><p>flag indicating weather weight norm in enabled or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Conv.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Conv.complex" title="Permalink to this definition"></a></dt>
<dd><p>False. Indicates synapse is not complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Conv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Conv.forward" title="Permalink to this definition"></a></dt>
<dd><p>Applies the synapse to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor. Typically spikes. Input is expected to be of shape
NCHWT.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dendrite accumulation / weighted spikes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.</span></span><span class="sig-name descname"><span class="pre">ConvTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ConvTranspose3d</span></code>, <a class="reference internal" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer" title="lava.lib.dl.slayer.synapse.layer.GenericLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericLayer</span></code></a></p>
<p>Transposed convolution synapse layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_features</strong> (<em>int</em>) – number of input features.</p></li>
<li><p><strong>out_features</strong> (<em>int</em>) – number of output features.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – size of the transposed convolution kernel.</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of the transposed convolution. Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the transposed convolution. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the transposed convolution. Defaults to 1.</p></li>
<li><p><strong>groups</strong> (<em>int</em>) – number of blocked connections from input channel to output channel.
Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose.in_channels">
<span class="sig-name descname"><span class="pre">in_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose.in_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose.weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose.kernel_size">
<span class="sig-name descname"><span class="pre">kernel_size</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose.kernel_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose.stride" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose.padding">
<span class="sig-name descname"><span class="pre">padding</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose.padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose.dilation">
<span class="sig-name descname"><span class="pre">dilation</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose.dilation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose.groups">
<span class="sig-name descname"><span class="pre">groups</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose.groups" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose.weight_norm_enabled">
<span class="sig-name descname"><span class="pre">weight_norm_enabled</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose.weight_norm_enabled" title="Permalink to this definition"></a></dt>
<dd><p>flag indicating weather weight norm in enabled or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose.complex" title="Permalink to this definition"></a></dt>
<dd><p>False. Indicates synapse is not complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.ConvTranspose.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.ConvTranspose.forward" title="Permalink to this definition"></a></dt>
<dd><p>Applies the synapse to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor. Typically spikes. Input is expected to be of shape
NCHWT.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dendrite accumulation / weighted spikes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Dense">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.</span></span><span class="sig-name descname"><span class="pre">Dense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Dense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Conv3d</span></code>, <a class="reference internal" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer" title="lava.lib.dl.slayer.synapse.layer.GenericLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericLayer</span></code></a></p>
<p>Dense synapse layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_neurons</strong> (<em>int</em>) – number of input neurons.</p></li>
<li><p><strong>out_neurons</strong> (<em>int</em>) – number of output neurons.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scaling factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Dense.in_channels">
<span class="sig-name descname"><span class="pre">in_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Dense.in_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Dense.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Dense.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Dense.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Dense.weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Dense.weight_norm_enabled">
<span class="sig-name descname"><span class="pre">weight_norm_enabled</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Dense.weight_norm_enabled" title="Permalink to this definition"></a></dt>
<dd><p>flag indicating weather weight norm in enabled or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Dense.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Dense.complex" title="Permalink to this definition"></a></dt>
<dd><p>False. Indicates synapse is not complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Dense.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Dense.forward" title="Permalink to this definition"></a></dt>
<dd><p>Applies the synapse to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor. Typically spikes. Input is expected to be of shape
NCT or NCHWT.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dendrite accumulation / weighted spikes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Pool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.</span></span><span class="sig-name descname"><span class="pre">Pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Pool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Conv3d</span></code>, <a class="reference internal" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer" title="lava.lib.dl.slayer.synapse.layer.GenericLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericLayer</span></code></a></p>
<p>Pooling synape layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – [description]</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of pooling. Defaults to <cite>kernel_size</cite>.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the pooling. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the pooling. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Pool.in_channels">
<span class="sig-name descname"><span class="pre">in_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Pool.in_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Pool.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Pool.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Pool.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Pool.weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Pool.kernel_size">
<span class="sig-name descname"><span class="pre">kernel_size</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Pool.kernel_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Pool.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Pool.stride" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Pool.padding">
<span class="sig-name descname"><span class="pre">padding</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Pool.padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Pool.dilation">
<span class="sig-name descname"><span class="pre">dilation</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Pool.dilation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Pool.weight_norm_enabled">
<span class="sig-name descname"><span class="pre">weight_norm_enabled</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Pool.weight_norm_enabled" title="Permalink to this definition"></a></dt>
<dd><p>flag indicating weather weight norm in enabled or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Pool.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Pool.complex" title="Permalink to this definition"></a></dt>
<dd><p>False. Indicates synapse is not complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Pool.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Pool.forward" title="Permalink to this definition"></a></dt>
<dd><p>Applies the synapse to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor. Typically spikes. Input is expected to be of shape
NCHWT.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dendrite accumulation / weighted spikes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Unpool">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.synapse.</span></span><span class="sig-name descname"><span class="pre">Unpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Unpool" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ConvTranspose3d</span></code>, <a class="reference internal" href="#lava.lib.dl.slayer.synapse.layer.GenericLayer" title="lava.lib.dl.slayer.synapse.layer.GenericLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericLayer</span></code></a></p>
<p>Unpooling synape layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – [description]</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – stride of unpooling. Defaults to <cite>kernel_size</cite>.</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – padding of the unpooling. Defaults to 0.</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em> of </em><em>two ints</em>) – dilation of the unpooling. Defaults to 1.</p></li>
<li><p><strong>weight_scale</strong> (<em>int</em>) – weight initialization scale factor. Defaults to 1.</p></li>
<li><p><strong>weight_norm</strong> (<em>bool</em>) – flag to enable/disable weight normalization. Defaults to False.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>optional</em>) – a function reference or a lambda function. If the function is provided,
it will be applied to it’s weight before the forward operation of the
synapse. Typically the function is a quantization mechanism of the
synapse. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For kernel_size, stride, padding and dilation, the tuple of two ints are
represented in (height, width) order. The integer value is broadcast to
height and width.</p>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Unpool.in_channels">
<span class="sig-name descname"><span class="pre">in_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Unpool.in_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Unpool.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Unpool.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Unpool.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Unpool.weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Unpool.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Unpool.stride" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Unpool.padding">
<span class="sig-name descname"><span class="pre">padding</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Unpool.padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Unpool.dilation">
<span class="sig-name descname"><span class="pre">dilation</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Unpool.dilation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Unpool.weight_norm_enabled">
<span class="sig-name descname"><span class="pre">weight_norm_enabled</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Unpool.weight_norm_enabled" title="Permalink to this definition"></a></dt>
<dd><p>flag indicating weather weight norm in enabled or not.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Unpool.complex">
<span class="sig-name descname"><span class="pre">complex</span></span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Unpool.complex" title="Permalink to this definition"></a></dt>
<dd><p>False. Indicates synapse is not complex.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.synapse.Unpool.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.synapse.Unpool.forward" title="Permalink to this definition"></a></dt>
<dd><p>Applies the synapse to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor. Typically spikes. Input is expected to be of shape
NCHWT.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dendrite accumulation / weighted spikes.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modules.html" class="btn btn-neutral float-left" title="Synapse" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../spike/modules.html" class="btn btn-neutral float-right" title="Spike" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Intel Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script> 

</body>
</html>