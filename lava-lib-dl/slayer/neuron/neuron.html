<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Neuron Modules &mdash; Lava  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Synapse" href="../synapse/modules.html" />
    <link rel="prev" title="Neuron" href="modules.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Lava
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../lava_architecture_overview.html">Lava Architecture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#key-attributes">Key attributes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#why-do-we-need-lava">Why do we need Lava?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#lava-s-foundational-concepts">Lava’s foundational concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#processes">1. Processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#behavioral-implementations-via-processmodels">2. Behavioral implementations via ProcessModels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#composability-and-connectivity">3. Composability and connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava_architecture_overview.html#cross-platform-execution">4. Cross-platform execution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava_architecture_overview.html#lava-software-stack">Lava software stack</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started_with_lava.html">Getting Started with Lava</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html">Installing Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#1.-System-Requirements">1. System Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#2.-Getting-Started">2. Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#2.1-Cloning-Lava-and-Running-from-Source">2.1 Cloning Lava and Running from Source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#2.2-[Alternative]-Installing-Lava-from-Binaries">2.2 [Alternative] Installing Lava from Binaries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#3.-Running-Lava-on-Intel-Loihi">3. Running Lava on Intel Loihi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#4.-Lava-Developer-Guide">4. Lava Developer Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#5.-Tutorials">5. Tutorials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial01_installing_lava.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html">Walk through Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#1.-Usage-of-the-Process-Library">1. Usage of the Process Library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Processes">Processes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Ports-and-connections">Ports and connections</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Variables">Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Record-internal-Vars-over-time">Record internal Vars over time</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Execution">Execution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Retrieve-recorded-data">Retrieve recorded data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Learn-more-about">Learn more about</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#2.-Create-a-custom-Process">2. Create a custom Process</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Create-a-new-ProcessModel">Create a new ProcessModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Use-the-custom-SpikeGenerator">Use the custom SpikeGenerator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#Execute-and-plot">Execute and plot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#id1">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#id2">Learn more about</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial00_tour_through_lava.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html">Processes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#What-is-a-Process?">What is a <em>Process</em>?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#How-to-build-a-Process?">How to build a <em>Process</em>?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Overall-architecture">Overall architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#AbstractProcess:-Defining-Vars,-Ports,-and-the-API"><em>AbstractProcess</em>: Defining <em>Vars</em>, <em>Ports</em>, and the API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#ProcessModel:-Defining-the-behavior-of-a-Process"><em>ProcessModel</em>: Defining the behavior of a <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Instantiating-the-Process">Instantiating the <em>Process</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Interacting-with-Processes">Interacting with <em>Processes</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Accessing-Vars">Accessing <em>Vars</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Using-custom-APIs">Using custom APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Executing-a-Process">Executing a <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#Update-Vars">Update <em>Vars</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial02_processes.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html"><em>ProcessModels</em></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Create-a-LIF-Process">Create a LIF <em>Process</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Create-a-Python-LeafProcessModel-that-implements-the-LIF-Process">Create a Python <em>LeafProcessModel</em> that implements the LIF <em>Process</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Setup">Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Defining-a-PyLifModel-for-LIF">Defining a <em>PyLifModel</em> for LIF</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Compile-and-run-PyLifModel">Compile and run <em>PyLifModel</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#Selecting-1-ProcessModel:-More-on-LeafProcessModel-attributes-and-relations">Selecting 1 <em>ProcessModel</em>: More on <em>LeafProcessModel</em> attributes and relations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial03_process_models.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html">Execution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Configuring-and-starting-execution">Configuring and starting execution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Run-conditions">Run conditions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Run-configurations">Run configurations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Running-multiple-Processes">Running multiple <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Pausing,-resuming,-and-stopping-execution">Pausing, resuming, and stopping execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#Manual-compilation-and-execution">Manual compilation and execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial04_execution.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html">Connect processes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Building-a-network-of-Processes">Building a network of <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Create-a-connection">Create a connection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Possible-connections">Possible connections</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#There-are-some-things-to-consider-though:">There are some things to consider though:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Connect-multiple-InPorts-from-a-single-OutPort">Connect multiple <em>InPorts</em> from a single <em>OutPort</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#Connecting-multiple-InPorts-to-a-single-OutPort">Connecting multiple <em>InPorts</em> to a single <em>OutPort</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial05_connect_processes.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html">Hierarchical <em>Processes</em> and <em>SubProcessModels</em></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-LIF-and-Dense-Processes-and-ProcessModels">Create LIF and Dense <em>Processes</em> and <em>ProcessModels</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-Dense-connection-Process">Create a Dense connection <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-Python-Dense-connection-ProcessModel-implementing-the-Loihi-Sync-Protocol-and-requiring-a-CPU-compute-resource">Create a Python Dense connection <em>ProcessModel</em> implementing the Loihi Sync Protocol and requiring a CPU compute resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-LIF-neuron-Process">Create a LIF neuron <em>Process</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-Python-LIF-neuron-ProcessModel-implementing-the-Loihi-Sync-Protocol-and-requiring-a-CPU-compute-resource">Create a Python LIF neuron <em>ProcessModel</em> implementing the Loihi Sync Protocol and requiring a CPU compute resource</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-DenseLayer-Hierarchical-Process-that-encompasses-Dense-and-LIF-Process-behavior">Create a DenseLayer Hierarchical <em>Process</em> that encompasses Dense and LIF <em>Process</em> behavior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Create-a-SubProcessModel-that-implements-the-DenseLayer-Process-using-Dense-and-LIF-child-Processes">Create a <em>SubProcessModel</em> that implements the DenseLayer <em>Process</em> using Dense and LIF child <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Run-the-DenseLayer-Process">Run the DenseLayer <em>Process</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#Run-Connected-DenseLayer-Processes">Run Connected DenseLayer <em>Processes</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial06_hierarchical_processes.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html">Remote Memory Access</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Recommended-tutorials-before-starting:">Recommended tutorials before starting:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Create-a-minimal-Process-and-ProcessModel-with-a-RefPort">Create a minimal <em>Process</em> and <em>ProcessModel</em> with a <em>RefPort</em></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Create-a-Python-Process-Model-implementing-the-Loihi-Sync-Protocol-and-requiring-a-CPU-compute-resource">Create a Python Process Model implementing the Loihi Sync Protocol and requiring a CPU compute resource</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Run-the-Processes">Run the <em>Processes</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Implicit-and-explicit-VarPorts">Implicit and explicit VarPorts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#Options-to-connect-RefPorts-and-VarPorts">Options to connect RefPorts and VarPorts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial07_remote_memory_access.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html">MNIST Digit Classification with Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#This-tutorial-gives-a-bird’s-eye-view-of">This tutorial gives a bird’s-eye view of</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Our-MNIST-Classifier">Our MNIST Classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#General-Imports">General Imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Lava-Processes">Lava Processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#ProcessModels-for-Python-execution">ProcessModels for Python execution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Connecting-Processes">Connecting Processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Execution-and-results">Execution and results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial01_mnist_digit_classification.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html">Excitatory-Inhibitory Neural Network with Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#This-tutorial-gives-a-high-level-view-of">This tutorial gives a high level view of</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#E/I-Network">E/I Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#General-imports">General imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#E/I-Network-Lava-Process">E/I Network Lava Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#ProcessModels-for-Python-execution">ProcessModels for Python execution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Rate-neurons">Rate neurons</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Defining-the-parameters-for-the-network">Defining the parameters for the network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Execution-and-Results">Execution and Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Visualizing-the-activity">Visualizing the activity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Further-analysis">Further analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Controlling-the-network">Controlling the network</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#LIF-Neurons">LIF Neurons</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#id7">Execution and Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#id8">Visualizing the activity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#id9">Controlling the network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#DIfferent-recurrent-activation-regimes">DIfferent recurrent activation regimes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Running-a-ProcessModel-bit-accurate-with-Loihi">Running a ProcessModel bit-accurate with Loihi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Execution-of-bit-accurate-model">Execution of bit accurate model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/end_to_end/tutorial02_excitatory_inhibitory_network.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html">Spike-timing Dependent Plasticity (STDP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#STDP-from-Lavas-Process-Library">STDP from Lavas Process Library</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#The-plastic-connection-Process">The plastic connection Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#Plot-spike-trains">Plot spike trains</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#Plot-traces">Plot traces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial08_stdp.html#Plot-STDP-learning-window-and-weight-changes">Plot STDP learning window and weight changes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html">Custom Learning Rules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#2.-Loihi’s-learning-engine">2. Loihi’s learning engine</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Epoch-based-updates">Epoch-based updates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Synaptic-variables">Synaptic variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Learning-rules">Learning rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Dependencies">Dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Scaling-factors">Scaling factors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Factors">Factors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Traces">Traces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Example:-Basic-pair-based-STDP">Example: Basic pair-based STDP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Instantiating-LearningRule">Instantiating LearningRule</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#The-plastic-connection-Process">The plastic connection Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Plot-spike-trains">Plot spike trains</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Plot-traces">Plot traces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Plot-STDP-learning-window-and-weight-changes">Plot STDP learning window and weight changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/tutorial09_custom_learning_rules.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html">Three Factor Learning with Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#This-tutorial-assumes-that-you:">This tutorial assumes that you:</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Defining-three-factor-learning-rule-interfaces-in-Lava">Defining three-factor learning rule interfaces in Lava</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Reward-modulated-Spike-Timing-Dependent-Plasticity-(R-STDP)-learning-rule">Reward-modulated Spike-Timing Dependent Plasticity (R-STDP) learning rule</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Defining-a-simple-learning-network-with-localized-reward-signals">Defining a simple learning network with localized reward signals</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Initialize-network-parameters-and-weights">Initialize network parameters and weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Generate-binary-input-and-graded-reward-spikes">Generate binary input and graded reward spikes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Initialize-Network-Processes">Initialize Network Processes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Connect-Network-Processes">Connect Network Processes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Create-monitors-to-observe-the-weight-and-trace-dynamics-during-learning">Create monitors to observe the weight and trace dynamics during learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Run-the-network">Run the network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Visualize-the-learning-results">Visualize the learning results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Plot-eligibility-trace-dynamics">Plot eligibility trace dynamics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Plot-reward-trace-dynamics">Plot reward trace dynamics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Advanced-Topic:-Implementing-custom-learning-rule-interfaces">Advanced Topic: Implementing custom learning rule interfaces</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#How-to-learn-more?">How to learn more?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/notebooks/in_depth/three_factor_learning/tutorial01_Reward_Modulated_STDP.html#Follow-the-links-below-for-deep-dive-tutorials-on-the-concepts-in-this-tutorial:">Follow the links below for deep-dive tutorials on the concepts in this tutorial:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../algorithms.html">Algorithms and Application Libraries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../dl.html">Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#lava-dl-workflow">Lava-DL Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#getting-started">Getting Started</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#slayer-2-0">SLAYER 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#bootstrap">Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code-1">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#network-exchange-netx-library">Network Exchange (NetX) Library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dl.html#example-code-2">Example Code</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dl.html#detailed-description">Detailed Description</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../slayer.html">Lava-DL SLAYER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/bootstrap.html">Lava-DL Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../netx/netx.html">Lava-DL NetX</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../dnf.html">Dynamic Neural Fields</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#what-is-lava-dnf">What is lava-dnf?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#key-features">Key features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dnf.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../optimization.html">Neuromorphic Constrained Optimization Library</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#about-the-project">About the Project</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#taxonomy-of-optimization-problems">Taxonomy of Optimization Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#optimizationsolver-and-optimizationproblem-classes">OptimizationSolver and OptimizationProblem Classes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#tutorials">Tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#quadratic-programming">Quadratic Programming</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#quadratic-uncosntrained-binary-optimization">Quadratic Uncosntrained Binary Optimization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#examples">Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#solving-qp-problems">Solving QP problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#solving-qubo">Solving QUBO</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../optimization.html#getting-started">Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#requirements">Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#installation">Installation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../optimization.html#alternative-installing-lava-via-conda">[Alternative] Installing Lava via Conda</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../developer_guide.html">Developer Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#lava-s-origins">Lava’s Origins</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#contact-information">Contact Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#development-roadmap">Development Roadmap</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#initial-release">Initial Release</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#how-to-contribute-to-lava">How to contribute to Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#open-an-issue">Open an Issue</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#pull-request-checklist">Pull Request Checklist</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#open-a-pull-request">Open a Pull Request</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#coding-conventions">Coding Conventions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#code-requirements">Code Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#guidelines">Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#docstring-format">Docstring Format</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#contributors">Contributors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#contributor">Contributor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#committer">Committer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-project-committers">List of lava-nc/lava Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-dnf-project-committers">List of lava-nc/lava-dnf Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-optimization-project-committers">List of lava-nc/lava-optimization Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#list-of-lava-nc-lava-dl-project-committers">List of lava-nc/lava-dl Project Committers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer_guide.html#committer-promotion">Committer Promotion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#repository-structure">Repository Structure</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#id17">lava-nc/lava</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-dnf">lava-nc/lava-dnf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-dl">lava-nc/lava-dl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-optimization">lava-nc/lava-optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../developer_guide.html#lava-nc-lava-docs">lava-nc/lava-docs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#code-of-conduct">Code of Conduct</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../developer_guide.html#licenses">Licenses</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../lava_api_documentation.html">Lava API Documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../lava/lava.html">Lava</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/lava.magma.html">Magma</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.magma.compiler.html">lava.magma.compiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.magma.core.html">lava.magma.core</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.magma.runtime.html">lava.magma.runtime</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/lava.proc.html">Lava process library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.conv.html">lava.proc.conv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.dense.html">lava.proc.dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.io.html">lava.proc.io</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.learning_rules.html">lava.proc.learning_rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.lif.html">lava.proc.lif</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.monitor.html">lava.proc.monitor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.receiver.html">lava.proc.receiver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.sdn.html">lava.proc.sdn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.proc.spiker.html">lava.proc.spiker</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava/lava.utils.html">Lava Utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.dataloader.html">lava.utils.dataloader</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-float2fixed">lava.utils.float2fixed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-profiler">lava.utils.profiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-system">lava.utils.system</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-validator">lava.utils.validator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-visualizer">lava.utils.visualizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava/lava.utils.html#lava-utils-weightutils">lava.utils.weightutils</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html">Lava - Deep Learning</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">SLAYER</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="modules.html">Neuron</a></li>
<li class="toctree-l4"><a class="reference internal" href="../synapse/modules.html">Synapse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../spike/modules.html">Spike</a></li>
<li class="toctree-l4"><a class="reference internal" href="../axon/modules.html">Axon</a></li>
<li class="toctree-l4"><a class="reference internal" href="../dendrite/modules.html">Dendrite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../block/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../loss.html">Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../classifier.html">Classifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../io.html">Input/Output</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto.html">Auto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../utils/modules.html">Utilities</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#indices-and-tables">Indices and tables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../bootstrap/index.html">Bootstrap (ANN-SNN training)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/block/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/ann_sampler.html">ANN Statistics Sampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bootstrap/routine.html">Routine</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../bootstrap/index.html#indices-and-tables">Indices and tables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../netx/index.html">Lava-DL NetX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../netx/blocks/modules.html">Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../netx/hdf5.html">HDF5</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../netx/utils.html">Utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../netx/index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.html">Lava - Dynamic Neural Fields</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.connect.html">lava.lib.dnf.connect</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.connect.html#lava-lib-dnf-connect-connect">lava.lib.dnf.connect.connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.connect.html#lava-lib-dnf-connect-exceptions">lava.lib.dnf.connect.exceptions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.kernels.html">lava.lib.dnf.kernels</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.kernels.html#lava-lib-dnf-kernels-kernels">lava.lib.dnf.kernels.kernels</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html">lava.lib.dnf.operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-enums">lava.lib.dnf.operations.enums</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-exceptions">lava.lib.dnf.operations.exceptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-operations">lava.lib.dnf.operations.operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.operations.html#lava-lib-dnf-operations-shape-handlers">lava.lib.dnf.operations.shape_handlers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.inputs.html">lava.lib.dnf.inputs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.inputs.gauss_pattern.html">lava.lib.dnf.inputs.gauss_pattern</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.inputs.rate_code_spike_gen.html">lava.lib.dnf.inputs.rate_code_spike_gen</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html">lava.lib.dnf.utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-convenience">lava.lib.dnf.utils.convenience</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-math">lava.lib.dnf.utils.math</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-plotting">lava.lib.dnf.utils.plotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-dnf/lava.lib.dnf.utils.html#lava-lib-dnf-utils-validation">lava.lib.dnf.utils.validation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.html">Lava - Optimization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html">lava.lib.optimization.problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.bayesian.html">lava.lib.optimization.problems.bayesian</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-coefficients">lava.lib.optimization.problems.coefficients</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-constraints">lava.lib.optimization.problems.constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-cost">lava.lib.optimization.problems.cost</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-problems">lava.lib.optimization.problems.problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.problems.html#lava-lib-optimization-problems-variables">lava.lib.optimization.problems.variables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.html">lava.lib.optimization.solvers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.bayesian.html">lava.lib.optimization.solvers.bayesian</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.generic.html">lava.lib.optimization.solvers.generic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.solvers.qp.html">lava.lib.optimization.solvers.qp</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.utils.html">lava.lib.optimization.utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.utils.generators.html">lava.lib.optimization.utils.generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../lava-lib-optimization/lava.lib.optimization.utils.html#lava-lib-optimization-utils-solver-tuner">lava.lib.optimization.utils.solver_tuner</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Lava</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../lava_api_documentation.html">Lava API Documentation</a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Lava - Deep Learning</a></li>
          <li class="breadcrumb-item"><a href="../index.html">SLAYER</a></li>
          <li class="breadcrumb-item"><a href="modules.html">Neuron</a></li>
      <li class="breadcrumb-item active">Neuron Modules</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/lava-lib-dl/slayer/neuron/neuron.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="neuron-modules">
<h1>Neuron Modules<a class="headerlink" href="#neuron-modules" title="Permalink to this heading"></a></h1>
<section id="module-lava.lib.dl.slayer.neuron.base">
<span id="abstract-neuron"></span><h2>Abstract Neuron<a class="headerlink" href="#module-lava.lib.dl.slayer.neuron.base" title="Permalink to this heading"></a></h2>
<p>Abstract neuron base class.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.base.Neuron">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.base.</span></span><span class="sig-name descname"><span class="pre">Neuron</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shared_param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complex</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.base.Neuron" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>This is an abstract class that governs the minimal basic functionality
of a neuron object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>float</em><em> or </em><em>torch tensor</em>) – neuron threshold.</p></li>
<li><p><strong>tau_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – controls the relaxation of spike function gradient. It determines
the scope of voltage/state around the neuron threshold that
effectively contributes to the error. Default is 1</p></li>
<li><p><strong>scale_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – controls the scale of spike function gradient. It controls the
gradient flow across layers. It should be increased if there is
vanishing gradient and increased if there is exploding gradient.
Default is 1</p></li>
<li><p><strong>p_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – scaling factor of neuron parameter. Default is 1</p></li>
<li><p><strong>w_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – scaling factor for dendrite input (weighted spikes). It’s good to
compute synaptic operations and its gradients on smaller range.
w_scale scales down the synaptic weights for quantization.
The actual synaptic weights must be descaled. Default is 1</p></li>
<li><p><strong>s_scale</strong> (<em>int</em><em>, </em><em>optional</em>) – scaling factor for neuron states. The fixed percision neuron states
are scaled down by s_scale so that they are in a reasonable range
for gradient flow. Default is 1</p></li>
<li><p><strong>norm</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – normalization function on the dendrite output. None means no
normalization. Default is None</p></li>
<li><p><strong>dropout</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – neuron dropout method. None means no dropout. Default is None</p></li>
<li><p><strong>persistent_state</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable persitent state between iterations.
Default is False</p></li>
<li><p><strong>shared_param</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable shared parameter for neuron group. If False,
idividual parameters are assigned on a per-channel basis.
Default is True</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable learnable neuron decays. Default is True</p></li>
<li><p><strong>complex</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to indicate real or complex neuron. Defaul</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">Neuron</span> <span class="pre">Attributes</span></span></dt>
<dd><p>threshold</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">Gradient</span> <span class="pre">Attributes</span></span></dt>
<dd><ul class="simple">
<li><p>tau_grad</p></li>
<li><p>scale_grad</p></li>
</ul>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">Scaling</span> <span class="pre">Atrributes</span></span></dt>
<dd><ul class="simple">
<li><p>p_scale</p></li>
<li><p>w_scale</p></li>
<li><p>s_scale</p></li>
</ul>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">Normalization</span> <span class="pre">Attributes</span></span></dt>
<dd><ul class="simple">
<li><p>norm</p></li>
</ul>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">Dropout</span> <span class="pre">Attributes</span></span></dt>
<dd><ul class="simple">
<li><p>dropout</p></li>
</ul>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">State</span> <span class="pre">Attributes</span></span></dt>
<dd><ul class="simple">
<li><p>persistent_state</p></li>
</ul>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">Group</span> <span class="pre">Attributes</span></span></dt>
<dd><ul class="simple">
<li><p>shared_param</p></li>
<li><p>complex</p></li>
</ul>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">Debug</span> <span class="pre">Attributes</span></span></dt>
<dd><ul class="simple">
<li><dl class="simple">
<dt>debug<span class="classifier">bool</span></dt><dd><p>It is False by default. There shall be no constructor access to this
flag. If desired, it should be explicitly set.</p>
</dd>
</dl>
</li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.base.Neuron.clamp">
<span class="sig-name descname"><span class="pre">clamp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.base.Neuron.clamp" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.base.Neuron.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.base.Neuron.device" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.base.Neuron.quantize_8bit">
<span class="sig-name descname"><span class="pre">quantize_8bit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">descale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.base.Neuron.quantize_8bit" title="Permalink to this definition"></a></dt>
<dd><p>Quantization method for 8 bit equivalent input when descaled.
This should be linked with synapse instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weight</strong> (<em>torch.tensor</em>) – synaptic weight.</p></li>
<li><p><strong>descale</strong> (<em>Bool</em>) – flag to scale/descale the weight (Default value = False)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>quantized weight.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>It can be used like a normal function. But the intended use is as
follows</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">synapse</span><span class="o">.</span><span class="n">pre_hook_fx</span> <span class="o">=</span> <span class="n">neuron</span><span class="o">.</span><span class="n">quantize_8bit</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.base.Neuron.threshold">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">threshold</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.base.Neuron.threshold" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.base.Neuron.v_th_mant">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">v_th_mant</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.base.Neuron.v_th_mant" title="Permalink to this definition"></a></dt>
<dd><p>Get voltage-threshold-mantessa parameter.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.base.Neuron.weight_exponent">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">weight_exponent</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.base.Neuron.weight_exponent" title="Permalink to this definition"></a></dt>
<dd><p>Get weight exponent.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.neuron.cuba">
<span id="current-based-leaky-integrate-and-fire-cuba-neuron"></span><h2>CUrrent BAsed Leaky Integrate and Fire (CUBA) Neuron<a class="headerlink" href="#module-lava.lib.dl.slayer.neuron.cuba" title="Permalink to this heading"></a></h2>
<p>CUBA neuron model.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.Neuron">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.cuba.</span></span><span class="sig-name descname"><span class="pre">Neuron</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">voltage_decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shared_param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graded_spike</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.Neuron" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.neuron.base.Neuron" title="lava.lib.dl.slayer.neuron.base.Neuron"><code class="xref py py-class docutils literal notranslate"><span class="pre">Neuron</span></code></a></p>
<p>This is the implementation of Loihi CUBA neuron.</p>
<div class="math">
<p><span class="math">u[t] &amp;= (1 - \alpha_u)\,u[t-1] + x[t] \

v[t] &amp;= (1 - \alpha_v)\,v[t-1] + u[t] + \text{bias} \

s[t] &amp;= v[t] \geq \vartheta \

v[t] &amp;= v[t]\,(1-s[t])</span></p>
</div><p>The internal state representations are scaled down compared to
the actual hardware implementation. This allows for a natural range of
synaptic weight values as well as the gradient parameters.</p>
<p>The neuron parameters like threshold, decays are represented as real
values. They internally get converted to fixed precision representation of
the hardware. It also provides properties to access the neuron
parameters in fixed precision states. The parameters are internally clamped
to the valid range.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>float</em>) – neuron threshold.</p></li>
<li><p><strong>current_decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – the fraction of current decay per time step. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code>
is False, then it can be specified as a tuple (min_decay, max_decay).</p></li>
<li><p><strong>voltage_decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – the fraction of voltage decay per time step. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is
False, then it can be specified as a tuple (min_decay, max_decay).</p></li>
<li><p><strong>tau_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – time constant of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – scale of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale</strong> (<em>int</em><em>, </em><em>optional</em>) – scale of the internal state. <code class="docutils literal notranslate"><span class="pre">scale=1</span></code> will result in values in the
range expected from the of Loihi hardware. Defaults to 1&lt;&lt;6.</p></li>
<li><p><strong>norm</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – normalization function on the dendrite output. None means no
normalization. Defaults to None.</p></li>
<li><p><strong>dropout</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – neuron dropout method. None means no normalization. Defaults to None.</p></li>
<li><p><strong>shared_param</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable shared parameter neuron group. If it is
False, individual parameters are assigned on a per-channel basis.
Defaults to True.</p></li>
<li><p><strong>persistent_state</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable persistent state between iterations. Defaults to
False.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable learning on neuron parameter. Defaults to False.</p></li>
<li><p><strong>graded_spike</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable graded spike output. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.Neuron.clamp">
<span class="sig-name descname"><span class="pre">clamp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.Neuron.clamp" title="Permalink to this definition"></a></dt>
<dd><p>A function to clamp the sin decay and cosine decay parameters to be
within valid range. The user will generally not need to call this
function.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.Neuron.cx_current_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_current_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.Neuron.cx_current_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment current decay parameter to be used for configuring
Loihi hardware.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.Neuron.cx_voltage_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_voltage_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.Neuron.cx_voltage_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment voltage decay parameter to be used for configuring
Loihi hardware.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.Neuron.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.Neuron.device" title="Permalink to this definition"></a></dt>
<dd><p>The device memory (cpu/cuda) where the object lives.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.Neuron.device_params">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device_params</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.Neuron.device_params" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of device parameters.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.Neuron.dynamics">
<span class="sig-name descname"><span class="pre">dynamics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.Neuron.dynamics" title="Permalink to this definition"></a></dt>
<dd><p>Computes the dynamics (without spiking behavior) of the neuron
instance to an input. The input shape must match with the neuron shape.
For the first time, the neuron shape is determined from the input
automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>torch tensor</em> – current response of the neuron.</p></li>
<li><p><em>torch tensor</em> – voltage response of the neuron.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.Neuron.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.Neuron.forward" title="Permalink to this definition"></a></dt>
<dd><p>Computes the full response of the neuron instance to an input.
The input shape must match with the neuron shape. For the first time,
the neuron shape is determined from the input automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike response of the neuron.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.Neuron.ref_delay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ref_delay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.Neuron.ref_delay" title="Permalink to this definition"></a></dt>
<dd><p>Refractory delay.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.Neuron.scale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scale</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.Neuron.scale" title="Permalink to this definition"></a></dt>
<dd><p>Scale difference between slayer representation and hardware
representation of the variable states.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.Neuron.spike">
<span class="sig-name descname"><span class="pre">spike</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">voltage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.Neuron.spike" title="Permalink to this definition"></a></dt>
<dd><p>Extracts spike points from the voltage timeseries. It assumes the
reset dynamics is already applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>voltage</strong> (<em>torch tensor</em>) – neuron voltage dynamics</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike output</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.cuba.neuron_params">
<span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.cuba.</span></span><span class="sig-name descname"><span class="pre">neuron_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.cuba.neuron_params" title="Permalink to this definition"></a></dt>
<dd><p>Translates device parameters to neuron parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device_params</strong> (<em>dictionary</em>) – dictionary of device parameter specification.</p></li>
<li><p><strong>scale</strong> (<em>int</em>) – neuron scale value. Default value = 1 &lt;&lt; 6.</p></li>
<li><p><strong>p_scale</strong> (<em>int</em>) – parameter scale value. Default value = 1 &lt;&lt; 12</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary of neuron parameters that can be used to initialize neuron
class.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.neuron.rf">
<span id="resonate-and-fire-r-f-neuron"></span><h2>Resonate and Fire (R&amp;F) Neuron<a class="headerlink" href="#module-lava.lib.dl.slayer.neuron.rf" title="Permalink to this heading"></a></h2>
<p>Resonate and Fire neuron.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.rf.</span></span><span class="sig-name descname"><span class="pre">Neuron</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">period</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shared_param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graded_spike</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.neuron.base.Neuron" title="lava.lib.dl.slayer.neuron.base.Neuron"><code class="xref py py-class docutils literal notranslate"><span class="pre">Neuron</span></code></a></p>
<p>This is the implementation of RF neuron.</p>
<div class="math">
<p><span class="math">\mathfrak{Re}(z[t]) &amp;= (1-\alpha)(\cos\phi\ \mathfrak{Re}(z[t-1])
    - \sin\phi\ \mathfrak{Im}(z[t-1]))
    + \mathfrak{Re}(x[t]) + \text{real bias} \

\mathfrak{Im}(z[t]) &amp;= (1-\alpha)(\sin\phi\ \mathfrak{Re}(z[t-1])
    + \cos\phi\ \mathfrak{Im}(z[t-1]))
    + \mathfrak{Im}(x[t]) + \text{imag bias}  \

s[t] &amp;= |z[t]| \geq \vartheta \text{ and } \arg(z[t])=0</span></p>
</div><p>The internal state representations are scaled down compared to
the actual hardware implementation. This allows for a natural range of
synaptic weight values as well as the gradient parameters.</p>
<p>The neuron parameters like threshold, decays are represented as real
values. They internally get converted to fixed precision representation of
the hardware. It also provides properties to access the neuron
parameters in fixed precision states. The parameters are internally clamped
to the valid range.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>float</em>) – neuron threshold.</p></li>
<li><p><strong>period</strong> (<em>float</em><em> or </em><em>tuple</em>) – period of the neuron. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is False, then it can be
specified as a tuple (min_period, max_period).</p></li>
<li><p><strong>decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – decay factor of the neuron. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is False, then it can
be specified as a tuple (min_decay, max_decay).</p></li>
<li><p><strong>tau_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – time constant of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – scale of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale</strong> (<em>int</em><em>, </em><em>optional</em>) – scale of the internal state. <code class="docutils literal notranslate"><span class="pre">scale=1</span></code> will result in values in the
range expected from the of Loihi hardware. Defaults to 1  &lt;&lt;  6.</p></li>
<li><p><strong>norm</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – normalization function on the dendrite output. None means no
normalization. Defaults to None.</p></li>
<li><p><strong>dropout</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – neuron dropout method. None means no normalization. Defaults to None.</p></li>
<li><p><strong>shared_param</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable shared parameter neuron group. If it is
False, individual parameters are assigned on a per-channel basis.
Defaults to True.</p></li>
<li><p><strong>persistent_state</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable persistent state between iterations. Defaults to
False.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable learning on neuron parameter. Defaults to False.</p></li>
<li><p><strong>graded_spike</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable graded spike output. Defaults to False.</p></li>
<li><p><strong>log_init</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, initialized the natural frequency in log spaced range.
Default is True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.clamp">
<span class="sig-name descname"><span class="pre">clamp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.clamp" title="Permalink to this definition"></a></dt>
<dd><p>A function to clamp the sin decay and cosine decay parameters to be
within valid range. The user will generally not need to call this
function.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.cx_cos_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_cos_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.cx_cos_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment cos decay parameter to be used for configuration.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.cx_sin_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_sin_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.cx_sin_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment sin decay parameter to be used for configuration.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.decay" title="Permalink to this definition"></a></dt>
<dd><p>The decay parameter of the neuron.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.device" title="Permalink to this definition"></a></dt>
<dd><p>The device memory (cpu/cuda) where the object lives.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.device_params">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device_params</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.device_params" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of device parameters.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.dynamics">
<span class="sig-name descname"><span class="pre">dynamics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.dynamics" title="Permalink to this definition"></a></dt>
<dd><p>Computes the dynamics (without spiking behavior) of the neuron
instance to a complex input tuple. The input shape must match with the
neuron shape. For the first time, the neuron shape is determined from
the input automatically. It is essentially a resonator dynamics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>tuple</em><em> of </em><em>torch tensors</em>) – Complex input tuple of tensor, i.e. (real_input, imag_input).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>torch tensor</em> – real response of the neuron.</p></li>
<li><p><em>torch tensor</em> – imaginary response of the neuron.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.forward" title="Permalink to this definition"></a></dt>
<dd><p>Computes the full response of the neuron instance to a complex
input tuple. The input shape must match with the neuron shape. For the
first time, the neuron shape is determined from the input
automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> – Complex input tuple of tensor, i.e. (real_input, imag_input).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike response of the neuron.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.frequency">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">frequency</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.frequency" title="Permalink to this definition"></a></dt>
<dd><p>The frequency of neuron oscillation.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.lam">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lam</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.lam" title="Permalink to this definition"></a></dt>
<dd><p>The lambda parameter of the neuron.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.period">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">period</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.period" title="Permalink to this definition"></a></dt>
<dd><p>The period of the neuron oscillation.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.scale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scale</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.scale" title="Permalink to this definition"></a></dt>
<dd><p>Scale difference between slayer representation and hardware
representation of the variable states.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.Neuron.spike">
<span class="sig-name descname"><span class="pre">spike</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">real</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imag</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.Neuron.spike" title="Permalink to this definition"></a></dt>
<dd><p>Extracts spike points from the real and imaginary states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>real</strong> (<em>torch tensor</em>) – real state</p></li>
<li><p><strong>imag</strong> (<em>torch tensor</em>) – imaginary state</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike output</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf.neuron_params">
<span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.rf.</span></span><span class="sig-name descname"><span class="pre">neuron_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf.neuron_params" title="Permalink to this definition"></a></dt>
<dd><p>Translates device parameters to neuron parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device_params</strong> (<em>dictionary</em>) – dictionary of device parameter specification.</p></li>
<li><p><strong>scale</strong> (<em>int</em>) – neuron scale value. Default value = 1 &lt;&lt; 6.</p></li>
<li><p><strong>p_scale</strong> (<em>int</em>) – parameter scale value. Default value = 1 &lt;&lt; 12</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary of neuron parameters that can be used to initialize neuron
class.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.neuron.rf_iz">
<span id="resonate-and-fire-izhikevich-r-f-iz-neuron"></span><h2>Resonate and Fire Izhikevich (R&amp;F Iz) Neuron<a class="headerlink" href="#module-lava.lib.dl.slayer.neuron.rf_iz" title="Permalink to this heading"></a></h2>
<p>Resonate and Fire Izhikevich neuron.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.rf_iz.</span></span><span class="sig-name descname"><span class="pre">Neuron</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">period</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shared_param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graded_spike</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.neuron.base.Neuron" title="lava.lib.dl.slayer.neuron.base.Neuron"><code class="xref py py-class docutils literal notranslate"><span class="pre">Neuron</span></code></a></p>
<p>This is the implementation of RF Izhikevich neuron.</p>
<div class="math">
<p><span class="math">\mathfrak{Re}(z[t]) &amp;= (1-\alpha)(\cos\phi\ \mathfrak{Re}(z[t-1])
    - \sin\phi\ \mathfrak{Im}(z[t-1]))
    + \mathfrak{Re}(x[t]) + \text{real bias} \

\mathfrak{Im}(z[t]) &amp;= (1-\alpha)(\sin\phi\ \mathfrak{Re}(z[t-1])
    + \cos\phi\ \mathfrak{Im}(z[t-1]))
    + \mathfrak{Im}(x[t]) + \text{imag bias}\

s[t] &amp;= \mathfrak{Im}(z[t]) \geq \vartheta \

\mathfrak{Re}(z[t]) &amp;= \mathfrak{Re}(z[t])\,(1-s[t])</span></p>
</div><p>The internal state representations are scaled down compared to
the actual hardware implementation. This allows for a natural range of
synaptic weight values as well as the gradient parameters.</p>
<p>The neuron parameters like threshold, decays are represented as real
values. They internally get converted to fixed precision representation of
the hardware. It also provides properties to access the neuron
parameters in fixed precision states. The parameters are internally clamped
to the valid range.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>float</em>) – neuron threshold.</p></li>
<li><p><strong>period</strong> (<em>float</em><em> or </em><em>tuple</em>) – period of the neuron. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is False, then it can be
specified as a tuple (min_period, max_period).</p></li>
<li><p><strong>decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – decay factor of the neuron. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is False, then it can
be specified as a tuple (min_decay, max_decay).</p></li>
<li><p><strong>tau_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – time constant of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – scale of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale</strong> (<em>int</em><em>, </em><em>optional</em>) – scale of the internal state. <code class="docutils literal notranslate"><span class="pre">scale=1</span></code> will result in values in the
range expected from the of Loihi hardware. Defaults to 1 &lt;&lt; 6.</p></li>
<li><p><strong>norm</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – normalization function on the dendrite output. None means no
normalization. Defaults to None.</p></li>
<li><p><strong>dropout</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – neuron dropout method. None means no normalization. Defaults to None.</p></li>
<li><p><strong>shared_param</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable shared parameter neuron group. If it is
False, individual parameters are assigned on a per-channel basis.
Defaults to True.</p></li>
<li><p><strong>persistent_state</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable persistent state between iterations. Defaults to
False.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable learning on neuron parameter. Defaults to False.</p></li>
<li><p><strong>graded_spike</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable graded spike output. Defaults to False.</p></li>
<li><p><strong>log_init</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, initialized the natural frequency in log spaced range.
Default is True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.clamp">
<span class="sig-name descname"><span class="pre">clamp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.clamp" title="Permalink to this definition"></a></dt>
<dd><p>A function to clamp the sin decay and cosine decay parameters to be
within valid range. The user will generally not need to call this
function.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.cx_cos_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_cos_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.cx_cos_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment cos decay parameter to be used for configuration.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.cx_sin_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_sin_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.cx_sin_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment sin decay parameter to be used for configuration.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.decay" title="Permalink to this definition"></a></dt>
<dd><p>The decay parameter of the neuron.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.device" title="Permalink to this definition"></a></dt>
<dd><p>The device memory (cpu/cuda) where the object lives.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.device_params">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device_params</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.device_params" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of device parameters.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.dynamics">
<span class="sig-name descname"><span class="pre">dynamics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.dynamics" title="Permalink to this definition"></a></dt>
<dd><p>Computes the dynamics (without spiking behavior) of the neuron
instance to a complex input tuple. The input shape must match with the
neuron shape. For the first time, the neuron shape is determined from
the input automatically. It is essentially a resonator dynamics with
Izhikevich reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>tuple</em><em> of </em><em>torch tensors</em>) – Complex input tuple of tensor, i.e. (real_input, imag_input).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>torch tensor</em> – real response of the neuron.</p></li>
<li><p><em>torch tensor</em> – imaginary response of the neuron.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.forward" title="Permalink to this definition"></a></dt>
<dd><p>Computes the full response of the neuron instance to a complex
input tuple. The input shape must match with the neuron shape. For the
first time, the neuron shape is determined from the input
automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> – Complex input tuple of tensor, i.e. (real_input, imag_input).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike response of the neuron.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.frequency">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">frequency</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.frequency" title="Permalink to this definition"></a></dt>
<dd><p>The frequency of neuron oscillation.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.lam">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lam</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.lam" title="Permalink to this definition"></a></dt>
<dd><p>The lambda parameter of the neuron.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.period">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">period</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.period" title="Permalink to this definition"></a></dt>
<dd><p>The period of the neuron oscillation.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.scale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scale</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.scale" title="Permalink to this definition"></a></dt>
<dd><p>Scale difference between slayer representation and hardware
representation of the variable states.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.Neuron.spike">
<span class="sig-name descname"><span class="pre">spike</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">real</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imag</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.Neuron.spike" title="Permalink to this definition"></a></dt>
<dd><p>Extracts spike points from the real and imaginary states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>real</strong> (<em>torch tensor</em>) – real state</p></li>
<li><p><strong>imag</strong> (<em>torch tensor</em>) – imaginary state</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike output</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.rf_iz.neuron_params">
<span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.rf_iz.</span></span><span class="sig-name descname"><span class="pre">neuron_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.rf_iz.neuron_params" title="Permalink to this definition"></a></dt>
<dd><p>Translates device parameters to neuron parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device_params</strong> (<em>dictionary</em>) – dictionary of device parameter specification.</p></li>
<li><p><strong>scale</strong> (<em>int</em>) – neuron scale value. Default value = 1 &lt;&lt; 6.</p></li>
<li><p><strong>p_scale</strong> (<em>int</em>) – parameter scale value. Default value = 1 &lt;&lt; 12</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary of neuron parameters that can be used to initialize neuron
class.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.neuron.alif">
<span id="adaptive-leaky-integrate-and-fire-alif-neuron"></span><h2>Adaptive Leaky Integrate and Fire (ALIF) Neuron<a class="headerlink" href="#module-lava.lib.dl.slayer.neuron.alif" title="Permalink to this heading"></a></h2>
<p>Adaptive Leaky Integrate and Fire neuron.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.alif.</span></span><span class="sig-name descname"><span class="pre">Neuron</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold_step</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">voltage_decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold_decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refractory_decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shared_param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graded_spike</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.neuron.base.Neuron" title="lava.lib.dl.slayer.neuron.base.Neuron"><code class="xref py py-class docutils literal notranslate"><span class="pre">Neuron</span></code></a></p>
<p>This is the implementation of Adaptive LIF neuron.</p>
<div class="math">
<p><span class="math">u[t] &amp;= (1-\alpha_u)\,u[t-1] + x[t] + \text{bias} \

v[t] &amp;= (1-\alpha_v)\,v[t-1] + u[t] \

\vartheta[t] &amp;= (1-\alpha_{\vartheta})\,(\vartheta[t-1]
    - \vartheta_0) + \vartheta_0 \

r[t] &amp;= (1-\alpha_r)\,r[t-1] \

s[t] &amp;= (v[t] - r[t]) \geq \vartheta[t] \

r[t] &amp;= r[t] + 2\,\vartheta[t] \

\vartheta[t] &amp;= \vartheta[t] + \vartheta_{\text{step}}</span></p>
</div><p>The internal state representations are scaled down compared to
the actual hardware implementation. This allows for a natural range of
synaptic weight values as well as the gradient parameters.</p>
<p>The neuron parameters like threshold, decays are represented as real
values. They internally get converted to fixed precision representation of
the hardware. It also provides properties to access the neuron
parameters in fixed precision states. The parameters are internally clamped
to the valid range.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>float</em>) – base neuron threshold.</p></li>
<li><p><strong>threshold_step</strong> (<em>float</em>) – the increase in threshold after spike.</p></li>
<li><p><strong>current_decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – the fraction of current decay per time step. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is
False, then it can be specified as a tuple (min_decay, max_decay).</p></li>
<li><p><strong>voltage_decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – the fraction of voltage decay per time step. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is
False, then it can be specified as a tuple (min_decay, max_decay).</p></li>
<li><p><strong>threshold_decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – the fraction of threshold decay per time step. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is
False, then it can be specified as a tuple (min_decay, max_decay).</p></li>
<li><p><strong>refractory_decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – the fraction of refractory decay per time step. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is
False, then it can be specified as a tuple (min_decay, max_decay).</p></li>
<li><p><strong>tau_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – time constant of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – scale of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale</strong> (<em>int</em><em>, </em><em>optional</em>) – scale of the internal state. <code class="docutils literal notranslate"><span class="pre">scale=1</span></code> will result in values in the
range expected from the of Loihi hardware. Defaults to 1 &lt;&lt; 6.</p></li>
<li><p><strong>norm</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – normalization function on the dendrite output. None means no
normalization. Defaults to None.</p></li>
<li><p><strong>dropout</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – neuron dropout method. None means no normalization. Defaults to None.</p></li>
<li><p><strong>shared_param</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable shared parameter neuron group. If it is
False, individual parameters are assigned on a per-channel basis.
Defaults to True.</p></li>
<li><p><strong>persistent_state</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable persistent state between iterations.
Defaults to False.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable learning on neuron parameter. Defaults to False.</p></li>
<li><p><strong>graded_spike</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable graded spike output. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.clamp">
<span class="sig-name descname"><span class="pre">clamp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.clamp" title="Permalink to this definition"></a></dt>
<dd><p>A function to clamp the sin decay and cosine decay parameters to be
within valid range. The user will generally not need to call this
function.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.cx_current_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_current_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.cx_current_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment current decay parameter to be used for configuring
Loihi hardware.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.cx_refractory_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_refractory_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.cx_refractory_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment refractory decay parameter to be used for
configuring Loihi hardware.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.cx_threshold_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_threshold_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.cx_threshold_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment threshold decay parameter to be used for configuring
Loihi hardware.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.cx_voltage_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_voltage_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.cx_voltage_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment voltage decay parameter to be used for configuring
Loihi hardware.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.device" title="Permalink to this definition"></a></dt>
<dd><p>The device memory (cpu/cuda) where the object lives.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.device_params">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device_params</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.device_params" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of device parameters.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.dynamics">
<span class="sig-name descname"><span class="pre">dynamics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.dynamics" title="Permalink to this definition"></a></dt>
<dd><p>Computes the dynamics (without spiking behavior) of the neuron
instance to an input. The input shape must match with the neuron shape.
For the first time, the neuron shape is determined from the input
automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>torch tensor</em> – current response of the neuron.</p></li>
<li><p><em>torch tensor</em> – voltage response of the neuron.</p></li>
<li><p><em>torch tensor</em> – adaptive threshold of the neuron.</p></li>
<li><p><em>torch tensor</em> – refractory response of the neuorn.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.forward" title="Permalink to this definition"></a></dt>
<dd><p>Computes the full response of the neuron instance to an input.
The input shape must match with the neuron shape. For the first time,
the neuron shape is determined from the input automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike response of the neuron.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.ref_delay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">ref_delay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.ref_delay" title="Permalink to this definition"></a></dt>
<dd><p>Refractory delay.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.scale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scale</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.scale" title="Permalink to this definition"></a></dt>
<dd><p>Scale difference between slayer representation and hardware
representation of the variable states.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.spike">
<span class="sig-name descname"><span class="pre">spike</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">voltage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refractory</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.spike" title="Permalink to this definition"></a></dt>
<dd><p>Extracts spike points from the voltage timeseries.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>voltage</strong> (<em>torch tensor</em>) – neuron voltage dynamics of the neuron.</p></li>
<li><p><strong>threshold</strong> (<em>torch tensor</em>) – threshold dynamics of the neuron.</p></li>
<li><p><strong>threshold</strong> – refractory dynamics of the neuron.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike output</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.Neuron.v_th_step">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">v_th_step</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.Neuron.v_th_step" title="Permalink to this definition"></a></dt>
<dd><p>Get voltage-threshold step parameter.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.alif.neuron_params">
<span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.alif.</span></span><span class="sig-name descname"><span class="pre">neuron_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.alif.neuron_params" title="Permalink to this definition"></a></dt>
<dd><p>Translates device parameters to neuron parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device_params</strong> (<em>dictionary</em>) – dictionary of device parameter specification.</p></li>
<li><p><strong>scale</strong> (<em>int</em>) – neuron scale value. Default value = 1 &lt;&lt; 6.</p></li>
<li><p><strong>p_scale</strong> (<em>int</em>) – parameter scale value. Default value = 1 &lt;&lt; 12</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary of neuron parameters that can be used to initialize neuron
class.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.neuron.adrf">
<span id="adaptive-resonate-and-fire-ad-r-f-neuron"></span><h2>Adaptive Resonate and Fire (Ad R&amp;F) Neuron<a class="headerlink" href="#module-lava.lib.dl.slayer.neuron.adrf" title="Permalink to this heading"></a></h2>
<p>Adaptive RF Izhikevich neuron.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.adrf.</span></span><span class="sig-name descname"><span class="pre">Neuron</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold_step</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">period</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold_decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refractory_decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shared_param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graded_spike</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.neuron.base.Neuron" title="lava.lib.dl.slayer.neuron.base.Neuron"><code class="xref py py-class docutils literal notranslate"><span class="pre">Neuron</span></code></a></p>
<p>This is the implementation of RF neuron.</p>
<div class="math">
<p><span class="math">\mathfrak{Re}(z[t]) &amp;= (1-\alpha)(\cos\phi\ \mathfrak{Re}(z[t-1])
    - \sin\phi\ \mathfrak{Im}(z[t-1]))
    + \mathfrak{Re}(x[t]) + \text{real bias}\

\mathfrak{Im}(z[t]) &amp;= (1-\alpha)(\sin\phi\ \mathfrak{Re}(z[t-1])
    + \cos\phi\ \mathfrak{Im}(z[t-1]))
    + \mathfrak{Im}(x[t]) + \text{imag bias} \

\vartheta[t] &amp;= (1-\alpha_{\vartheta})\,
    (\vartheta[t-1] - \vartheta_0) + \vartheta_0 \

r[t] &amp;= (1-\alpha_r)\,r[t-1] \

s[t] &amp;= |z[t]| \geq (\vartheta[t] + r[t]) \text{ and } \arg(z[t])=0</span></p>
</div><p>The internal state representations are scaled down compared to
the actual hardware implementation. This allows for a natural range of
synaptic weight values as well as the gradient parameters.</p>
<p>The neuron parameters like threshold, decays are represented as real
values. They internally get converted to fixed precision representation of
the hardware. It also provides properties to access the neuron
parameters in fixed precision states. The parameters are internally clamped
to the valid range.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>float</em>) – neuron threshold.</p></li>
<li><p><strong>threshold_step</strong> (<em>float</em>) – the increase in threshold after spike.</p></li>
<li><p><strong>period</strong> (<em>float</em><em> or </em><em>tuple</em>) – period of the neuron. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is False, then it can be
specified as a tuple (min_period, max_period).</p></li>
<li><p><strong>decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – decay factor of the neuron. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is False, then it can
be specified as a tuple (min_decay, max_decay).</p></li>
<li><p><strong>threshold_decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – the fraction of threshold decay per time step. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is
False, then it can be specified as a tuple : min_decay, max_decay).</p></li>
<li><p><strong>refractory_decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – the fraction of refractory decay per time step. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is
False, then it can be specified as a tuple : min_decay, max_decay).</p></li>
<li><p><strong>tau_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – time constant of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – scale of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale</strong> (<em>int</em><em>, </em><em>optional</em>) – scale of the internal state. <code class="docutils literal notranslate"><span class="pre">scale=1</span></code> will result in values in the
range expected from the of Loihi hardware. Defaults to 1  &lt;&lt;  6.</p></li>
<li><p><strong>norm</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – normalization function on the dendrite output. None means no
normalization. Defaults to None.</p></li>
<li><p><strong>dropout</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – neuron dropout method. None means no normalization. Defaults to None.</p></li>
<li><p><strong>shared_param</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable shared parameter neuron group. If it is
False, individual parameters are assigned on a per-channel basis.
Defaults to True.</p></li>
<li><p><strong>persistent_state</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable persistent state between iterations.
Defaults to False.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable learning on neuron parameter. Defaults to False.</p></li>
<li><p><strong>graded_spike</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable graded spike output. Defaults to False.</p></li>
<li><p><strong>log_init</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, initialized the natural frequency in log spaced range.
Default is True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.clamp">
<span class="sig-name descname"><span class="pre">clamp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.clamp" title="Permalink to this definition"></a></dt>
<dd><p>A function to clamp the sin decay and cosine decay parameters to be
within valid range. The user will generally not need to call this
function.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.cx_cos_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_cos_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.cx_cos_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment cos decay parameter to be used for configuration.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.cx_refractory_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_refractory_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.cx_refractory_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment refractory decay parameter to be used for
configuring Loihi hardware.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.cx_sin_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_sin_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.cx_sin_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment sin decay parameter to be used for configuration.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.cx_threshold_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_threshold_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.cx_threshold_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment threshold decay parameter to be used for configuring
Loihi hardware.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.decay" title="Permalink to this definition"></a></dt>
<dd><p>The decay parameter of the neuron.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.device" title="Permalink to this definition"></a></dt>
<dd><p>The device memory (cpu/cuda) where the object lives.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.device_params">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device_params</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.device_params" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of device parameters.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.dynamics">
<span class="sig-name descname"><span class="pre">dynamics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.dynamics" title="Permalink to this definition"></a></dt>
<dd><p>Computes the dynamics (without spiking behavior) of the neuron
instance to a complex input tuple. The input shape must match with the
neuron shape. For the first time, the neuron shape is determined from
the input automatically. It is essentially a resonator dynamics with
adaptive threshold and refractory response.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>tuple</em><em> of </em><em>torch tensors</em>) – Complex input tuple of tensor, i.e. (real_input, imag_input).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>torch tensor</em> – real response of the neuron.</p></li>
<li><p><em>torch tensor</em> – imaginary response of the neuron.</p></li>
<li><p><em>torch tensor</em> – adaptive threshold of the neuron.</p></li>
<li><p><em>torch tensor</em> – refractory response of the neuorn.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.forward" title="Permalink to this definition"></a></dt>
<dd><p>omputes the full response of the neuron instance to a complex
input tuple. The input shape must match with the neuron shape. For the
first time, the neuron shape is determined from the input
automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> – Complex input tuple of tensor, i.e. (real_input, imag_input).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike response of the neuron.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.frequency">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">frequency</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.frequency" title="Permalink to this definition"></a></dt>
<dd><p>The frequency of neuron oscillation.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.lam">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lam</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.lam" title="Permalink to this definition"></a></dt>
<dd><p>The lambda parameter of the neuron.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.period">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">period</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.period" title="Permalink to this definition"></a></dt>
<dd><p>The period of the neuron oscillation.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.scale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scale</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.scale" title="Permalink to this definition"></a></dt>
<dd><p>Scale difference between slayer representation and hardware
representation of the variable states.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.spike">
<span class="sig-name descname"><span class="pre">spike</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">real</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refractory</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.spike" title="Permalink to this definition"></a></dt>
<dd><p>Extracts spike points from the real and imaginary states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>real</strong> (<em>torch tensor</em>) – real dynamics of the neuron.</p></li>
<li><p><strong>imag</strong> (<em>torch tensor</em>) – imaginary dynamics of the neuron.</p></li>
<li><p><strong>threshold</strong> (<em>torch tensor</em>) – threshold dynamics of the neuron.</p></li>
<li><p><strong>refractory</strong> (<em>torch tensor</em>) – refractory dynamics of the neuron.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike output</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.Neuron.v_th_step">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">v_th_step</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.Neuron.v_th_step" title="Permalink to this definition"></a></dt>
<dd><p>Get voltage-threshold step parameter.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf.neuron_params">
<span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.adrf.</span></span><span class="sig-name descname"><span class="pre">neuron_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf.neuron_params" title="Permalink to this definition"></a></dt>
<dd><p>Translates device parameters to neuron parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device_params</strong> (<em>dictionary</em>) – dictionary of device parameter specification.</p></li>
<li><p><strong>scale</strong> (<em>int</em>) – neuron scale value. Default value = 1 &lt;&lt; 6.</p></li>
<li><p><strong>p_scale</strong> (<em>int</em>) – parameter scale value. Default value = 1 &lt;&lt; 12</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary of neuron parameters that can be used to initialize neuron
class.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.neuron.adrf_iz">
<span id="adaptive-resonate-and-fire-izhikevich-ad-r-f-iz-neuron"></span><h2>Adaptive Resonate and Fire Izhikevich (Ad R&amp;F Iz) Neuron<a class="headerlink" href="#module-lava.lib.dl.slayer.neuron.adrf_iz" title="Permalink to this heading"></a></h2>
<p>Adaptive RF Izhikevich neuron.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">Neuron</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold_step</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">period</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold_decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refractory_decay</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shared_param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">graded_spike</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.neuron.base.Neuron" title="lava.lib.dl.slayer.neuron.base.Neuron"><code class="xref py py-class docutils literal notranslate"><span class="pre">Neuron</span></code></a></p>
<p>This is the implementation of Adaptive RF Izhikevich neuron.</p>
<div class="math">
<p><span class="math">\mathfrak{Re}(z[t]) &amp;= (1-\alpha)(\cos\phi\ \mathfrak{Re}(z[t-1])
    - \sin\phi\ \mathfrak{Im}(z[t-1]))
    + \mathfrak{Re}(x[t]) + \text{real bias}\

\mathfrak{Im}(z[t]) &amp;= (1-\alpha)(\sin\phi\ \mathfrak{Re}(z[t-1])
    + \cos\phi\ \mathfrak{Im}(z[t-1]))
    + \mathfrak{Im}(x[t]) + \text{imag bias}\

\vartheta[t] &amp;= (1-\alpha_{\vartheta})\,
    (\vartheta[t-1] - \vartheta_0) + \vartheta_0 \

r[t] &amp;= (1-\alpha_r)\,r[t-1] \

s[t] &amp;= \mathfrak{Im}(z[t]) \geq (\vartheta[t] + r[t])</span></p>
</div><p>The internal state representations are scaled down compared to
the actual hardware implementation. This allows for a natural range of
synaptic weight values as well as the gradient parameters.</p>
<p>The neuron parameters like threshold, decays are represented as real
values. They internally get converted to fixed precision representation of
the hardware. It also provides properties to access the neuron
parameters in fixed precision states. The parameters are internally clamped
to the valid range.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>float</em>) – neuron threshold.</p></li>
<li><p><strong>threshold_step</strong> (<em>float</em>) – the increase in threshold after spike.</p></li>
<li><p><strong>period</strong> (<em>float</em><em> or </em><em>tuple</em>) – period of the neuron. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is False, then it can be
specified as a tuple (min_period, max_period).</p></li>
<li><p><strong>decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – decay factor of the neuron. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is False, then it can
be specified as a tuple (min_decay, max_decay).</p></li>
<li><p><strong>threshold_decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – the fraction of threshold decay per time step. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is
False, then it can be specified as a tuple : min_decay, max_decay).</p></li>
<li><p><strong>refractory_decay</strong> (<em>float</em><em> or </em><em>tuple</em>) – the fraction of refractory decay per time step. If <code class="docutils literal notranslate"><span class="pre">shared_param</span></code> is
False, then it can be specified as a tuple : min_decay, max_decay).</p></li>
<li><p><strong>tau_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – time constant of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – scale of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale</strong> (<em>int</em><em>, </em><em>optional</em>) – scale of the internal state. <code class="docutils literal notranslate"><span class="pre">scale=1</span></code> will result in values in the
range expected from the of Loihi hardware. Defaults to 1 &lt;&lt; 6.</p></li>
<li><p><strong>norm</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – normalization function on the dendrite output. None means no
normalization. Defaults to None.</p></li>
<li><p><strong>dropout</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – neuron dropout method. None means no normalization. Defaults to None.</p></li>
<li><p><strong>shared_param</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable shared parameter neuron group. If it is
False, individual parameters are assigned on a per-channel basis.
Defaults to True.</p></li>
<li><p><strong>persistent_state</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable persistent state between iterations.
Defaults to False.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable learning on neuron parameter. Defaults to False.</p></li>
<li><p><strong>graded_spike</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable graded spike output. Defaults to False.</p></li>
<li><p><strong>log_init</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, initialized the natural frequency in log spaced range.
Default is True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.clamp">
<span class="sig-name descname"><span class="pre">clamp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.clamp" title="Permalink to this definition"></a></dt>
<dd><p>A function to clamp the sin decay and cosine decay parameters to be
within valid range. The user will generally not need to call this
function.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.cx_cos_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_cos_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.cx_cos_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment cos decay parameter to be used for configuration.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.cx_refractory_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_refractory_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.cx_refractory_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment refractory decay parameter to be used for
configuring Loihi hardware.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.cx_sin_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_sin_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.cx_sin_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment sin decay parameter to be used for configuration.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.cx_threshold_decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cx_threshold_decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.cx_threshold_decay" title="Permalink to this definition"></a></dt>
<dd><p>The compartment threshold decay parameter to be used for configuring
Loihi hardware.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.decay">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">decay</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.decay" title="Permalink to this definition"></a></dt>
<dd><p>The decay parameter of the neuron.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.device" title="Permalink to this definition"></a></dt>
<dd><p>The device memory (cpu/cuda) where the object lives.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.device_params">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device_params</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.device_params" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of device parameters.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.dynamics">
<span class="sig-name descname"><span class="pre">dynamics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.dynamics" title="Permalink to this definition"></a></dt>
<dd><p>Computes the dynamics (without spiking behavior) of the neuron
instance to a complex input tuple. The input shape must match with the
neuron shape. For the first time, the neuron shape is determined from
the input automatically. It is essentially a resonator dynamics with
Izhikevich firing with adaptive threshold and refractory response.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>tuple</em><em> of </em><em>torch tensors</em>) – Complex input tuple of tensor, i.e. (real_input, imag_input).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>torch tensor</em> – real response of the neuron.</p></li>
<li><p><em>torch tensor</em> – imaginary response of the neuron.</p></li>
<li><p><em>torch tensor</em> – adaptive threshold of the neuron.</p></li>
<li><p><em>torch tensor</em> – refractory response of the neuorn.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.forward" title="Permalink to this definition"></a></dt>
<dd><p>Computes the full response of the neuron instance to a complex
input tuple. The input shape must match with the neuron shape. For the
first time, the neuron shape is determined from the input
automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>tuple</em><em> of </em><em>torch tensors</em>) – Complex input tuple of tensor, i.e. (real_input, imag_input).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike response of the neuron.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.frequency">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">frequency</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.frequency" title="Permalink to this definition"></a></dt>
<dd><p>The frequency of neuron oscillation.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.lam">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lam</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.lam" title="Permalink to this definition"></a></dt>
<dd><p>The lambda parameter of the neuron.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.period">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">period</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.period" title="Permalink to this definition"></a></dt>
<dd><p>The period of the neuron oscillation.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.scale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scale</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.scale" title="Permalink to this definition"></a></dt>
<dd><p>Scale difference between slayer representation and hardware
representation of the variable states.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.spike">
<span class="sig-name descname"><span class="pre">spike</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">real</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refractory</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.spike" title="Permalink to this definition"></a></dt>
<dd><p>Extracts spike points from the real and imaginary states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>real</strong> (<em>torch tensor</em>) – real dynamics of the neuron.</p></li>
<li><p><strong>imag</strong> (<em>torch tensor</em>) – imaginary dynamics of the neuron.</p></li>
<li><p><strong>threshold</strong> (<em>torch tensor</em>) – threshold dynamics of the neuron.</p></li>
<li><p><strong>refractory</strong> (<em>torch tensor</em>) – refractory dynamics of the neuron.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>spike output</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.Neuron.v_th_step">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">v_th_step</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.Neuron.v_th_step" title="Permalink to this definition"></a></dt>
<dd><p>Get voltage-threshold step parameter.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.adrf_iz.neuron_params">
<span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.adrf_iz.</span></span><span class="sig-name descname"><span class="pre">neuron_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.adrf_iz.neuron_params" title="Permalink to this definition"></a></dt>
<dd><p>Translates device parameters to neuron parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device_params</strong> (<em>dictionary</em>) – dictionary of device parameter specification.</p></li>
<li><p><strong>scale</strong> (<em>int</em>) – neuron scale value. Default value = 1 &lt;&lt; 6.</p></li>
<li><p><strong>p_scale</strong> (<em>int</em>) – parameter scale value. Default value = 1 &lt;&lt; 12</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary of neuron parameters that can be used to initialize neuron
class.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.neuron.sigma_delta">
<span id="sigma-delta-neuron-sdn"></span><h2>Sigma Delta Neuron (SDN)<a class="headerlink" href="#module-lava.lib.dl.slayer.neuron.sigma_delta" title="Permalink to this heading"></a></h2>
<p>Sigma Delta neuron.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.sigma_delta.Neuron">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">Neuron</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cum_error</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shared_param</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.sigma_delta.Neuron" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lava.lib.dl.slayer.neuron.base.Neuron" title="lava.lib.dl.slayer.neuron.base.Neuron"><code class="xref py py-class docutils literal notranslate"><span class="pre">Neuron</span></code></a></p>
<p>This is the implementation of Sigma-Delta wrapper neuron.</p>
<p>The internal state representations are scaled down compared to
the actual hardware implementation. This allows for a natural range of
synaptic weight values as well as the gradient parameters.</p>
<p>The neuron parameters like threshold, decays are represented as real
values. They internally get converted to fixed precision representation of
the hardware. It also provides properties to access the neuron
parameters in fixed precision states. The parameters are internally clamped
to the valid range.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>float</em>) – neuron threshold.</p></li>
<li><p><strong>activation</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em>) – The neuron activation class instance that needs to be wrapped
by sigma-delta unit. For e.g. <code class="docutils literal notranslate"><span class="pre">torch.nn.functional.relu</span></code> would
give sigma-delta-relu unit.</p></li>
<li><p><strong>tau_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – time constant of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale_grad</strong> (<em>float</em><em>, </em><em>optional</em>) – scale of spike function derivative. Defaults to 1.</p></li>
<li><p><strong>scale</strong> (<em>int</em><em>, </em><em>optional</em>) – scale of the internal state. <cite>scale=1</cite> will result in values in the
range expected from the of Loihi hardware. Defaults to 1 &lt;&lt; 6.</p></li>
<li><p><strong>cum_error</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable residual state of delta unit. Defaults to False.</p></li>
<li><p><strong>norm</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – normalization function on the dendrite output. None means no
normalization. Defaults to None.</p></li>
<li><p><strong>dropout</strong> (<em>fx-ptr</em><em> or </em><em>lambda</em><em>, </em><em>optional</em>) – neuron dropout method. None means no normalization. Defaults to None.</p></li>
<li><p><strong>shared_param</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable shared parameter neuron group. If it is
False, individual parameters are assigned on a per-channel basis.
Defaults to True.</p></li>
<li><p><strong>persistent_state</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable persistent state between iterations.
Defaults to False.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to enable/disable learning on neuron parameter. Defaults to False.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.sigma_delta.Neuron.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.sigma_delta.Neuron.device" title="Permalink to this definition"></a></dt>
<dd><p>The device memory (cpu/cuda) where the object lives.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.sigma_delta.Neuron.device_params">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device_params</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.sigma_delta.Neuron.device_params" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of device parameters.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.sigma_delta.Neuron.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.sigma_delta.Neuron.forward" title="Permalink to this definition"></a></dt>
<dd><p>Computes the full response of the neuron instance to an input.
The input shape must match with the neuron shape. For the first time,
the neuron shape is determined from the input automatically.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input</strong> (<em>torch tensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>graded spike response of the neuron.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.sigma_delta.Neuron.scale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">scale</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.sigma_delta.Neuron.scale" title="Permalink to this definition"></a></dt>
<dd><p>Scale difference between slayer representation and hardware
representation of the variable states.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.sigma_delta.Neuron.set_bias">
<span class="sig-name descname"><span class="pre">set_bias</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bias</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.sigma_delta.Neuron.set_bias" title="Permalink to this definition"></a></dt>
<dd><p>Sets the bias for sigma-delta unit</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>bias</strong> (<em>torch tensor</em>) – bias corresponding to each neuron.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.sigma_delta.Neuron.threshold">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">threshold</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.sigma_delta.Neuron.threshold" title="Permalink to this definition"></a></dt>
<dd><p>Neuron threshold</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.sigma_delta.neuron_params">
<span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.sigma_delta.</span></span><span class="sig-name descname"><span class="pre">neuron_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.sigma_delta.neuron_params" title="Permalink to this definition"></a></dt>
<dd><p>Translates device parameters to neuron parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device_params</strong> (<em>dictionary</em>) – dictionary of device parameter specification.</p></li>
<li><p><strong>scale</strong> (<em>int</em>) – neuron scale value. Default value = 1  &lt;&lt;  6.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dictionary of neuron parameters that can be used to initialize neuron
class.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.neuron.dropout">
<span id="neuron-dropout"></span><h2>Neuron Dropout<a class="headerlink" href="#module-lava.lib.dl.slayer.neuron.dropout" title="Permalink to this heading"></a></h2>
<p>Neuron Dropout.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.dropout.Dropout">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.dropout.</span></span><span class="sig-name descname"><span class="pre">Dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.dropout.Dropout" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout3d</span></code></p>
<p>Neuron dropout method. It behaves similar to <cite>torch.nn.Dropout</cite>.
However, dropout over time dimension is preserved, i.e. if a neuron is
dropped, it remains dropped for the entire time duration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>float</em>) – dropout probability.</p></li>
<li><p><strong>inplace</strong> (<em>bool</em>) – inplace operation flag. Default is False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">drop</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">drop</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.dropout.Dropout.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.dropout.Dropout.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.neuron.norm">
<span id="neuron-normalization"></span><h2>Neuron Normalization<a class="headerlink" href="#module-lava.lib.dl.slayer.neuron.norm" title="Permalink to this heading"></a></h2>
<p>Neuron normalization methods.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.norm.</span></span><span class="sig-name descname"><span class="pre">MeanOnlyBatchNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Implements mean only batch norm with optional user defined quantization
using pre-hook-function. The mean of batchnorm translates to negative bias
of the neuron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> (<em>int</em>) – number of features. It is automatically initialized on first run if the
value is None. Default is None.</p></li>
<li><p><strong>momentum</strong> (<em>float</em>) – momentum of mean calculation. Defaults to 0.1.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>function pointer</em><em> or </em><em>lambda</em>) – pre-hook-function that is applied to the normalization output.
User can provide a quantization method as needed.
Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.num_features">
<span class="sig-name descname"><span class="pre">num_features</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.num_features" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.momentum">
<span class="sig-name descname"><span class="pre">momentum</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.momentum" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.pre_hook_fx">
<span class="sig-name descname"><span class="pre">pre_hook_fx</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.pre_hook_fx" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.running_mean">
<span class="sig-name descname"><span class="pre">running_mean</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.running_mean" title="Permalink to this definition"></a></dt>
<dd><p>running mean estimate.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.update">
<span class="sig-name descname"><span class="pre">update</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.update" title="Permalink to this definition"></a></dt>
<dd><p>enable mean estimte update.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.bias">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bias</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.bias" title="Permalink to this definition"></a></dt>
<dd><p>Equivalent bias shift.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.MeanOnlyBatchNorm.reset_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Reset states.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.norm.</span></span><span class="sig-name descname"><span class="pre">WgtScaleBatchNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_exp_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre_hook_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Implements batch norm with variance scale in powers of 2. This allows
eventual normalizaton to be implemented with bit-shift in a hardware
friendly manner. Optional user defined quantization can be enabled using a
pre-hook-function. The mean of batchnorm translates to negative bias of the
neuron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> (<em>int</em>) – number of features. It is automatically initialized on first run if the
value is None. Default is None.</p></li>
<li><p><strong>momentum</strong> (<em>float</em>) – momentum of mean calculation. Defaults to 0.1.</p></li>
<li><p><strong>weight_exp_bits</strong> (<em>int</em>) – number of allowable bits for weight exponentation. Defaults to 3.</p></li>
<li><p><strong>eps</strong> (<em>float</em>) – infitesimal value. Defaults to 1e-5.</p></li>
<li><p><strong>pre_hook_fx</strong> (<em>function pointer</em><em> or </em><em>lambda</em>) – pre-hook-function that is applied to the normalization output.
User can provide a quantization method as needed.
Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.num_features">
<span class="sig-name descname"><span class="pre">num_features</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.num_features" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.momentum">
<span class="sig-name descname"><span class="pre">momentum</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.momentum" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.weight_exp_bits">
<span class="sig-name descname"><span class="pre">weight_exp_bits</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.weight_exp_bits" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.eps">
<span class="sig-name descname"><span class="pre">eps</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.eps" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.pre_hook_fx">
<span class="sig-name descname"><span class="pre">pre_hook_fx</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.pre_hook_fx" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.running_mean">
<span class="sig-name descname"><span class="pre">running_mean</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.running_mean" title="Permalink to this definition"></a></dt>
<dd><p>running mean estimate.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.running_var">
<span class="sig-name descname"><span class="pre">running_var</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.running_var" title="Permalink to this definition"></a></dt>
<dd><p>running variance estimate.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.update">
<span class="sig-name descname"><span class="pre">update</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.update" title="Permalink to this definition"></a></dt>
<dd><p>enable mean estimte update.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.bias">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bias</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.bias" title="Permalink to this definition"></a></dt>
<dd><p>Equivalent bias shift.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.reset_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Reset states.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.std">
<span class="sig-name descname"><span class="pre">std</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">var</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.std" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.weight_exp">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">weight_exp</span></span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.norm.WgtScaleBatchNorm.weight_exp" title="Permalink to this definition"></a></dt>
<dd><p>Equivalent weight exponent value.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-lava.lib.dl.slayer.neuron">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-lava.lib.dl.slayer.neuron" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.Dropout">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lava.lib.dl.slayer.neuron.</span></span><span class="sig-name descname"><span class="pre">Dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.Dropout" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout3d</span></code></p>
<p>Neuron dropout method. It behaves similar to <cite>torch.nn.Dropout</cite>.
However, dropout over time dimension is preserved, i.e. if a neuron is
dropped, it remains dropped for the entire time duration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>float</em>) – dropout probability.</p></li>
<li><p><strong>inplace</strong> (<em>bool</em>) – inplace operation flag. Default is False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">drop</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">drop</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="lava.lib.dl.slayer.neuron.Dropout.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lava.lib.dl.slayer.neuron.Dropout.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modules.html" class="btn btn-neutral float-left" title="Neuron" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../synapse/modules.html" class="btn btn-neutral float-right" title="Synapse" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Intel Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script> 

</body>
</html>